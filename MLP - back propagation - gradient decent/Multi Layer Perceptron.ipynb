{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18267e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "816301b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value:\n",
    "  \n",
    "  def __init__(self, data, _children=(), _op='', label=''):\n",
    "    self.data = data\n",
    "    self.grad = 0.0\n",
    "    self._backward = lambda: None\n",
    "    self._prev = set(_children)\n",
    "    self._op = _op\n",
    "    self.label = label\n",
    "\n",
    "  def __repr__(self):\n",
    "    return f\"Value(data={self.data})\"\n",
    "  \n",
    "  def __add__(self, other):\n",
    "    other = other if isinstance(other, Value) else Value(other)\n",
    "    out = Value(self.data + other.data, (self, other), '+')\n",
    "    \n",
    "    def _backward():\n",
    "      self.grad += 1.0 * out.grad\n",
    "      other.grad += 1.0 * out.grad\n",
    "    out._backward = _backward\n",
    "    \n",
    "    return out\n",
    "\n",
    "  def __mul__(self, other):\n",
    "    other = other if isinstance(other, Value) else Value(other)\n",
    "    out = Value(self.data * other.data, (self, other), '*')\n",
    "    \n",
    "    def _backward():\n",
    "      self.grad += other.data * out.grad\n",
    "      other.grad += self.data * out.grad\n",
    "    out._backward = _backward\n",
    "      \n",
    "    return out\n",
    "  \n",
    "  def __pow__(self, other):\n",
    "    assert isinstance(other, (int, float)), \"only supporting int/float powers for now\"\n",
    "    out = Value(self.data**other, (self,), f'**{other}')\n",
    "\n",
    "    def _backward():\n",
    "        self.grad += other * (self.data ** (other - 1)) * out.grad\n",
    "    out._backward = _backward\n",
    "\n",
    "    return out\n",
    "  \n",
    "  def __rmul__(self, other): # other * self\n",
    "    return self * other\n",
    "\n",
    "  def __truediv__(self, other): # self / other\n",
    "    return self * other**-1\n",
    "\n",
    "  def __neg__(self): # -self\n",
    "    return self * -1\n",
    "\n",
    "  def __sub__(self, other): # self - other\n",
    "    return self + (-other)\n",
    "\n",
    "  def __radd__(self, other): # other + self\n",
    "    return self + other\n",
    "\n",
    "  def tanh(self):\n",
    "    x = self.data\n",
    "    t = (math.exp(2*x) - 1)/(math.exp(2*x) + 1)\n",
    "    out = Value(t, (self, ), 'tanh')\n",
    "    \n",
    "    def _backward():\n",
    "      self.grad += (1 - t**2) * out.grad\n",
    "    out._backward = _backward\n",
    "    \n",
    "    return out\n",
    "  \n",
    "  def exp(self):\n",
    "    x = self.data\n",
    "    out = Value(math.exp(x), (self, ), 'exp')\n",
    "    \n",
    "    def _backward():\n",
    "      self.grad += out.data * out.grad # NOTE: in the video I incorrectly used = instead of +=. Fixed here.\n",
    "    out._backward = _backward\n",
    "    \n",
    "    return out\n",
    "  \n",
    "  \n",
    "  def backward(self):\n",
    "    \n",
    "    topo = []\n",
    "    visited = set()\n",
    "    def build_topo(v):\n",
    "      if v not in visited:\n",
    "        visited.add(v)\n",
    "        for child in v._prev:\n",
    "          build_topo(child)\n",
    "        topo.append(v)\n",
    "    build_topo(self)\n",
    "    \n",
    "    self.grad = 1.0\n",
    "    for node in reversed(topo):\n",
    "      node._backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6688aeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "  \n",
    "  def __init__(self, nin):\n",
    "    self.w = [Value(random.uniform(-1,1)) for _ in range(nin)]\n",
    "    self.b = Value(random.uniform(-1,1))\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    # w * x + b\n",
    "    act = sum((wi*xi for wi, xi in zip(self.w, x)), self.b)\n",
    "    out = act.tanh()\n",
    "    return out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return self.w + [self.b]\n",
    "\n",
    "class Layer:\n",
    "  \n",
    "  def __init__(self, nin, nout):\n",
    "    self.neurons = [Neuron(nin) for _ in range(nout)]\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    outs = [n(x) for n in self.neurons]\n",
    "    return outs[0] if len(outs) == 1 else outs\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [p for neuron in self.neurons for p in neuron.parameters()]\n",
    "\n",
    "class MLP:\n",
    "  \n",
    "  def __init__(self, nin, nouts):\n",
    "    sz = [nin] + nouts\n",
    "    self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    for layer in self.layers:\n",
    "      x = layer(x)\n",
    "    return x\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d712d885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(data=-0.467580682178557)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1\n",
    "x = [2.0, 3.0, -1.0] # inputs\n",
    "n = MLP(3, [4, 4, 1]) # MLP(inputs, layers=(4 node layer, 4 node layer, 1 node layer - output))\n",
    "n(x) # passing the inputs to the Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "29e7d34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Value(data=-0.467580682178557),\n",
       " Value(data=-0.7937318142582119),\n",
       " Value(data=-0.334029126970337),\n",
       " Value(data=-0.26969308494363764)]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2\n",
    "xs = [\n",
    "  [2.0, 3.0, -1.0], # expected result = 1.0\n",
    "  [3.0, -1.0, 0.5], # expected result = -1.0\n",
    "  [0.5, 1.0, 1.0], # expected result = -1.0\n",
    "  [1.0, 1.0, -1.0], # expected result = 1.0\n",
    "] # list of groups of inputs\n",
    "ys = [1.0, -1.0, -1.0, 1.0] # desired targets for each group of inputs\n",
    "\n",
    "ypred = [n(x) for x in xs] # predicted results from MLP for each group of inputs\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a461f354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(data=4.251977356830471)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating Loss value for example 2 - using mean square error function for loss\n",
    "list_of_losses = [(yout - ygt)**2 for ygt, yout in zip(ys, ypred)]\n",
    "# zip ex: a = [1,2,3] b = [a,b,c] zip(a,b) = [[1,a],[2,b],[3,c]]\n",
    "# ygt means Y ground truth which is the expected result\n",
    "\n",
    "list_of_losses\n",
    "# returned a list of losses for each group of inputs\n",
    "\n",
    "loss = sum(list_of_losses)\n",
    "# total loss = the sum of all losses of expected results\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "12bbecbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.297664602657766"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating grade of nodes with derivative \n",
    "\n",
    "# because ypred is a list of output nodes of the MLP and we apply - and ** to those nodes which are instances of Value that has a -,** method\n",
    "# it means that the result of list of losses and loss itself are Value objects\n",
    "\n",
    "# losses = loss of ys0 + loss of ys1 + loss of ys2 + loss of ys3\n",
    "# loss of ys0 = object MLP + loss function -> loss function = (ys0 - ygt0)**2 -> object MLP is a graph with the output node ys0\n",
    "\n",
    "# doing backward() on loss will spread the gradient (derivate) to the loss function but also to the MLP\n",
    "# due to that we have, 1) how much the nodes affect the loss function, but also, 2) how much the nodes affect the output node ys0\n",
    "\n",
    "loss.backward() # always do one calculation per MLP creation because derivates add up and can acumulate\n",
    "n.layers[0].neurons[0].w[0].grad\n",
    "# how much this affects the loss or the output results\n",
    "# first layer, first neuron, first weight (one weight per input on a neuron, each neuron has 3 inputs), gradient derivative\n",
    "\n",
    "# the goal is to get a prediction or results as close as the ygt y ground truth value (expected result) to reduce loss as close to zero we can\n",
    "# if we make a Weight with a possitive gradient higher we will get a higher output\n",
    "# if we make a Weight with a negative gradient lower we will get a lower output\n",
    "# if the output is closer to the expected result we will get a lower loss\n",
    "# if the output is farther from the expected result we will get a higher loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c25fd6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Value(data=-0.3583313394887),\n",
       " Value(data=-0.30611862768222275),\n",
       " Value(data=-0.6088959513388303),\n",
       " Value(data=0.35247194902681844),\n",
       " Value(data=-0.12697716158392014),\n",
       " Value(data=0.5063229217066136),\n",
       " Value(data=0.6009473590299907),\n",
       " Value(data=-0.21902848976868872),\n",
       " Value(data=0.6651874938402131),\n",
       " Value(data=0.04134328015762678),\n",
       " Value(data=0.02930934542114083),\n",
       " Value(data=0.07584833581811146),\n",
       " Value(data=-0.7201009178657736),\n",
       " Value(data=-0.7782069461436816),\n",
       " Value(data=-0.9950470436667604),\n",
       " Value(data=-0.29110565245512765),\n",
       " Value(data=0.3912326396202157),\n",
       " Value(data=0.6233286921256274),\n",
       " Value(data=-0.0614045130081331),\n",
       " Value(data=0.3819372480198273),\n",
       " Value(data=-0.40869117974083813),\n",
       " Value(data=0.46776635669121935),\n",
       " Value(data=-0.9145900914267369),\n",
       " Value(data=-0.4011992047077457),\n",
       " Value(data=-0.4857809090020808),\n",
       " Value(data=-0.3036490107170904),\n",
       " Value(data=-0.46246937649994146),\n",
       " Value(data=0.48731652527256886),\n",
       " Value(data=0.17173448987386908),\n",
       " Value(data=0.168633044763272),\n",
       " Value(data=0.8383907382479572),\n",
       " Value(data=0.9119571435993725),\n",
       " Value(data=0.09527576177268027),\n",
       " Value(data=-0.2861971691539662),\n",
       " Value(data=0.6695575746923281),\n",
       " Value(data=0.6683260872830448),\n",
       " Value(data=0.6843352529112248),\n",
       " Value(data=-0.3706664146725187),\n",
       " Value(data=0.3228195587695142),\n",
       " Value(data=0.8069450002683698),\n",
       " Value(data=-0.06563585538142735)]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting all the parameters of the MLP - values we can interact with to change the output (weights and biases)\n",
    "\n",
    "n.parameters()\n",
    "# node1w1,node1w2,node1w3,node1bias,node2w1,node2w2,node2w3,node2bias, ... \n",
    "# has all the objects inside we can modify them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5b3bdb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'g': -2.297664602657766, 'w': -0.3583313394887}\n"
     ]
    }
   ],
   "source": [
    "# Gradient decent\n",
    "\n",
    "# we modify each parameter by a tiny STEP size in the direction of the gradient\n",
    "\n",
    "# following the direction can get us closer to the loss\n",
    "print({\"g\": n.layers[0].neurons[0].w[0].grad, \"w\": n.layers[0].neurons[0].w[0].data})\n",
    "# 1) if grad is negative means that making W bigger the lost will be lower\n",
    "# 2) if grad is possitive means that making W smaller the lost will be lower\n",
    "\n",
    "# if the amount to add is (step * grad) means:\n",
    "# 1) if grad is negative, W must get bigger -> (step(negative) * grad(negative)) -> step must be negative to cancel the grad\n",
    "# 2) if grad is possitive, W must get smaller -> (step(negative) * grad(possitive)) -> step must be negative to take out the grad\n",
    "\n",
    "# the previous is \"following the direction of the gradient\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c3b8267f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3353546934621223"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing the weights\n",
    "stepSign = -1\n",
    "\n",
    "# update - stocaistic gradient decent update - just adding the product of grad * step\n",
    "\n",
    "# no batching - means we do an update in all the data, when the data is too large, batching is a must and we only do an update in a batch\n",
    "# that can be grabbed randomly\n",
    "\n",
    "for p in n.parameters():\n",
    "    p.data += stepSign * 0.01 * p.grad\n",
    "    \n",
    "n.layers[0].neurons[0].w[0].data\n",
    "# new weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5fa16306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Value(data=-0.24400936649583502), Value(data=-0.739663299092658), Value(data=-0.21871892658341632), Value(data=-0.025416361134800725)]\n",
      "{'old loss': Value(data=4.251977356830471), 'new loss': Value(data=3.2772133311305924)}\n"
     ]
    }
   ],
   "source": [
    "ypred = [n(x) for x in xs] # predicted results from MLP for each group of inputs\n",
    "print(ypred)\n",
    "# Calculating Loss after changing weights\n",
    "new_loss = sum([(yout - ygt)**2 for ygt, yout in zip(ys, ypred)])\n",
    "print({\"old loss\": loss, \"new loss\": new_loss})\n",
    "loss = new_loss\n",
    "loss.backward() # backward pass -> recalculate gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "12538051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected result:\n",
      "\n",
      "[1.0, -1.0, -1.0, 1.0]\n",
      "---------------------------------------\n",
      "\n",
      "[Value(data=-0.24400936649583502), Value(data=-0.739663299092658), Value(data=-0.21871892658341632), Value(data=-0.025416361134800725)]\n",
      "0 {'loss': 3.2772133311305924}\n",
      "[Value(data=0.8322184977334336), Value(data=-0.3353220845100484), Value(data=0.3341790388394802), Value(data=0.783633287348134)]\n",
      "1 {'loss': 2.296795625865308}\n",
      "[Value(data=0.15801968722824927), Value(data=-0.8315572548017955), Value(data=-0.5300314627113144), Value(data=0.5061898403834525)]\n",
      "2 {'loss': 1.2020227052869092}\n",
      "[Value(data=0.8832532219089855), Value(data=-0.7274375413201406), Value(data=-0.0587105071435734), Value(data=0.8266276054380944)]\n",
      "3 {'loss': 1.0040040006342805}\n",
      "[Value(data=0.7454817956057705), Value(data=-0.8752411770477271), Value(data=-0.6390090343577011), Value(data=0.7329122928186784)]\n",
      "4 {'loss': 0.28199460087523415}\n",
      "[Value(data=0.7720799486677041), Value(data=-0.8864065753652879), Value(data=-0.6710445768678128), Value(data=0.7737847705541506)]\n",
      "5 {'loss': 0.22423601636087298}\n",
      "[Value(data=0.7896141141480056), Value(data=-0.8960684777270423), Value(data=-0.6994443749964941), Value(data=0.8002377485224466)]\n",
      "6 {'loss': 0.18530262312433202}\n",
      "[Value(data=0.8034486190894811), Value(data=-0.9039800555261706), Value(data=-0.7226960296814945), Value(data=0.8197699600904386)]\n",
      "7 {'loss': 0.1572326343147979}\n",
      "[Value(data=0.8149577831442226), Value(data=-0.9105153174373782), Value(data=-0.7418555975219931), Value(data=0.8350191036462548)]\n",
      "8 {'loss': 0.13610535912464614}\n",
      "[Value(data=0.824773917173987), Value(data=-0.9159995071935774), Value(data=-0.7578990305824354), Value(data=0.8473392743840766)]\n",
      "9 {'loss': 0.11967843943277547}\n",
      "[Value(data=0.833280990936435), Value(data=-0.9206720431671429), Value(data=-0.7715465239660007), Value(data=0.8575414937540866)]\n",
      "10 {'loss': 0.10657356943224675}\n",
      "[Value(data=0.8407431987823367), Value(data=-0.9247066418206668), Value(data=-0.7833179103160847), Value(data=0.8661529438354841)]\n",
      "11 {'loss': 0.09589798095369907}\n",
      "[Value(data=0.8473538123112623), Value(data=-0.928230955266048), Value(data=-0.7935929391023273), Value(data=0.8735348689540442)]\n",
      "12 {'loss': 0.08704895855681569}\n",
      "[Value(data=0.8532593133105948), Value(data=-0.9313405101489599), Value(data=-0.8026543478622089), Value(data=0.8799444986925179)]\n",
      "13 {'loss': 0.07960558448856415}\n",
      "[Value(data=0.8585734115870896), Value(data=-0.934108119815718), Value(data=-0.8107167668119408), Value(data=0.8855705845984029)]\n",
      "14 {'loss': 0.07326545325961101}\n",
      "[Value(data=0.8633859972221939), Value(data=-0.9365902435291188), Value(data=-0.8179460866160978), Value(data=0.8905550738641241)]\n",
      "15 {'loss': 0.06780600220595157}\n",
      "[Value(data=0.8677691947103179), Value(data=-0.9388313449939857), Value(data=-0.8244726283272269), Value(data=0.8950069427046884)]\n",
      "16 {'loss': 0.06305999050937104}\n",
      "[Value(data=0.8717816135043421), Value(data=-0.9408669338747795), Value(data=-0.8304002707356698), Value(data=0.8990113492906486)]\n",
      "17 {'loss': 0.058899449883549074}\n",
      "[Value(data=0.8754714135241368), Value(data=-0.9427257275279826), Value(data=-0.8358129000674374), Value(data=0.902635872299585)]\n",
      "18 {'loss': 0.05522488828400346}\n",
      "[Value(data=0.8788785625589804), Value(data=-0.9444312145588327), Value(data=-0.8407790526084173), Value(data=0.9059348713767404)]\n",
      "19 {'loss': 0.051957851034368785}\n",
      "[Value(data=0.8820365273246868), Value(data=-0.9460028042990271), Value(data=-0.8453553143236998), Value(data=0.9089526018824688)]\n",
      "20 {'loss': 0.04903568554108242}\n",
      "[Value(data=0.8849735589921677), Value(data=-0.947456684648241), Value(data=-0.8495888497079919), Value(data=0.9117254826273367)]\n",
      "21 {'loss': 0.046407786668624426}\n",
      "[Value(data=0.887713683136612), Value(data=-0.9488064711559857), Value(data=-0.8535193101211367), Value(data=0.9142837750723802)]\n",
      "22 {'loss': 0.04403285807347812}\n",
      "[Value(data=0.890277470937025), Value(data=-0.950063704397986), Value(data=-0.8571802928956298), Value(data=0.9166528456779331)]\n",
      "23 {'loss': 0.04187688387339163}\n",
      "[Value(data=0.8926826462963335), Value(data=-0.9512382355588722), Value(data=-0.8606004704486342), Value(data=0.9188541279003541)]\n",
      "24 {'loss': 0.03991160547532408}\n",
      "[Value(data=0.8949445683968665), Value(data=-0.9523385285629895), Value(data=-0.8638044737116795), Value(data=0.9209058644122735)]\n",
      "25 {'loss': 0.0381133632341839}\n",
      "[Value(data=0.897076618648687), Value(data=-0.9533718991623075), Value(data=-0.8668135903750984), Value(data=0.9228236862404336)]\n",
      "26 {'loss': 0.03646220533080492}\n",
      "[Value(data=0.8990905135162501), Value(data=-0.9543447058701757), Value(data=-0.8696463219465301), Value(data=0.9246210693370522)]\n",
      "27 {'loss': 0.03494119491445202}\n",
      "[Value(data=0.9009965593457553), Value(data=-0.9552625037346238), Value(data=-0.8723188320276722), Value(data=0.9263096979524166)]\n",
      "28 {'loss': 0.03353586610411495}\n",
      "[Value(data=0.9028038614171697), Value(data=-0.9561301691606543), Value(data=-0.8748453099530966), Value(data=0.9278997563739668)]\n",
      "29 {'loss': 0.032233792984955344}\n",
      "[Value(data=0.904520496578375), Value(data=-0.9569520019764738), Value(data=-0.8772382679757408), Value(data=0.9294001650580026)]\n",
      "30 {'loss': 0.031024245250906933}\n",
      "[Value(data=0.9061536566886653), Value(data=-0.9577318094644004), Value(data=-0.8795087858338169), Value(data=0.9308187731959864)]\n",
      "31 {'loss': 0.029897910917412025}\n",
      "[Value(data=0.907709768500148), Value(data=-0.9584729759868659), Value(data=-0.8816667133237487), Value(data=0.9321625168567826)]\n",
      "32 {'loss': 0.028846671408493875}\n",
      "[Value(data=0.909194594394825), Value(data=-0.9591785210234602), Value(data=-0.8837208391103586), Value(data=0.9334375497105848)]\n",
      "33 {'loss': 0.02786341787868241}\n",
      "[Value(data=0.9106133174702634), Value(data=-0.9598511478208517), Value(data=-0.8856790322038669), Value(data=0.9346493517514404)]\n",
      "34 {'loss': 0.026941900249326488}\n",
      "[Value(data=0.9119706137546004), Value(data=-0.960493284390295), Value(data=-0.8875483611648135), Value(data=0.9358028202416683)]\n",
      "35 {'loss': 0.02607660238665063}\n",
      "[Value(data=0.9132707137790859), Value(data=-0.9611071182291723), Value(data=-0.8893351950497584), Value(data=0.9369023461965391)]\n",
      "36 {'loss': 0.025262638311005243}\n",
      "[Value(data=0.9145174553046139), Value(data=-0.9616946258660912), Value(data=-0.891045289301261), Value(data=0.9379518790356608)]\n",
      "37 {'loss': 0.024495665433788578}\n",
      "[Value(data=0.9157143286590436), Value(data=-0.9622575981134425), Value(data=-0.892683859156017), Value(data=0.9389549814941899)]\n",
      "38 {'loss': 0.023771811663582443}\n",
      "[Value(data=0.9168645158731932), Value(data=-0.9627976617422472), Value(data=-0.8942556426517508), Value(data=0.9399148764727868)]\n",
      "39 {'loss': 0.023087613873117488}\n",
      "[Value(data=0.9179709245892107), Value(data=-0.9633162981606868), Value(data=-0.8957649549244325), Value(data=0.9408344871812637)]\n",
      "40 {'loss': 0.02243996572239422}\n",
      "[Value(data=0.9190362175434253), Value(data=-0.9638148595717345), Value(data=-0.8972157351785888), Value(data=0.9417164716757516)]\n",
      "41 {'loss': 0.021826073226290304}\n",
      "[Value(data=0.9200628382875734), Value(data=-0.9642945830006394), Value(data=-0.8986115874669222), Value(data=0.9425632526870389)]\n",
      "42 {'loss': 0.02124341676360739}\n",
      "[Value(data=0.9210530337003768), Value(data=-0.9647566025149907), Value(data=-0.8999558162174531), Value(data=0.9433770434765415)]\n",
      "43 {'loss': 0.020689718468373676}\n",
      "[Value(data=0.9220088737503817), Value(data=-0.9652019599051492), Value(data=-0.901251457286515), Value(data=0.9441598703271027)]\n",
      "44 {'loss': 0.020162914138049704}\n",
      "[Value(data=0.9229322688965087), Value(data=-0.9656316140482232), Value(data=-0.9025013051862056), Value(data=0.9449135921716144)]\n",
      "45 {'loss': 0.019661128948198964}\n",
      "[Value(data=0.9238249854516157), Value(data=-0.9660464491423756), Value(data=-0.9037079370290512), Value(data=0.9456399177779913)]\n",
      "46 {'loss': 0.019182656387672567}\n",
      "[Value(data=0.9246886591839207), Value(data=-0.9664472819684191), Value(data=-0.904873733645945), Value(data=0.9463404208402398)]\n",
      "47 {'loss': 0.018725939928887596}\n",
      "[Value(data=0.9255248073893608), Value(data=-0.966834868311105), Value(data=-0.9060008982620392), Value(data=0.9470165532690813)]\n",
      "48 {'loss': 0.018289557029365154}\n",
      "[Value(data=0.9263348396332056), Value(data=-0.9672099086522016), Value(data=-0.9070914730562659), Value(data=0.9476696569293134)]\n",
      "49 {'loss': 0.017872205127212822}\n",
      "[Value(data=0.927120067330244), Value(data=-0.9675730532306123), Value(data=-0.9081473538812005), Value(data=0.9483009740329035)]\n",
      "50 {'loss': 0.01747268934770481}\n",
      "[Value(data=0.927881712308552), Value(data=-0.9679249065507278), Value(data=-0.9091703033791619), Value(data=0.948911656365141)]\n",
      "51 {'loss': 0.017089911682912927}\n",
      "[Value(data=0.9286209144814239), Value(data=-0.9682660314084673), Value(data=-0.9101619626963162), Value(data=0.9495027734948269)]\n",
      "52 {'loss': 0.016722861443329413}\n",
      "[Value(data=0.9293387387348018), Value(data=-0.9685969524945905), Value(data=-0.9111238619678981), Value(data=0.950075320097468)]\n",
      "53 {'loss': 0.016370606811087124}\n",
      "[Value(data=0.9300361811229486), Value(data=-0.9689181596265597), Value(data=-0.9120574297235174), Value(data=0.9506302225019828)]\n",
      "54 {'loss': 0.016032287349898675}\n",
      "[Value(data=0.9307141744527259), Value(data=-0.9692301106531991), Value(data=-0.9129640013411322), Value(data=0.9511683445559057)]\n",
      "55 {'loss': 0.01570710734813886}\n",
      "[Value(data=0.9313735933262773), Value(data=-0.9695332340704564), Value(data=-0.9138448266609557), Value(data=0.9516904928909612)]\n",
      "56 {'loss': 0.015394329889351807}\n",
      "[Value(data=0.9320152587029159), Value(data=-0.9698279313814889), Value(data=-0.914701076855864), Value(data=0.9521974216597854)]\n",
      "57 {'loss': 0.01509327155947317}\n",
      "[Value(data=0.9326399420332872), Value(data=-0.9701145792299917), Value(data=-0.9155338506423158), Value(data=0.9526898368051356)]\n",
      "58 {'loss': 0.014803297712718665}\n",
      "[Value(data=0.9332483690122578), Value(data=-0.970393531331977), Value(data=-0.9163441799050557), Value(data=0.9531683999148985)]\n",
      "59 {'loss': 0.01452381822880289}\n",
      "[Value(data=0.9338412229912654), Value(data=-0.9706651202280517), Value(data=-0.917133034799668), Value(data=0.9536337317093379)]\n",
      "60 {'loss': 0.01425428370324083}\n",
      "[Value(data=0.9344191480859396), Value(data=-0.9709296588755025), Value(data=-0.9179013283891182), Value(data=0.9540864152011382)]\n",
      "61 {'loss': 0.013994182020222245}\n",
      "[Value(data=0.934982752010543), Value(data=-0.9711874420971577), Value(data=-0.9186499208635889), Value(data=0.9545269985637483)]\n",
      "62 {'loss': 0.013743035264148884}\n",
      "[Value(data=0.9355326086670743), Value(data=-0.9714387479019487), Value(data=-0.9193796233870104), Value(data=0.9549559977391691)]\n",
      "63 {'loss': 0.01350039693157504}\n",
      "[Value(data=0.9360692605136659), Value(data=-0.9716838386903426), Value(data=-0.9200912016085664), Value(data=0.9553738988125723)]\n",
      "64 {'loss': 0.013265849410137379}\n",
      "[Value(data=0.9365932207341049), Value(data=-0.9719229623562811), Value(data=-0.920785378873003), Value(data=0.9557811601778801)]\n",
      "65 {'loss': 0.013039001695228728}\n",
      "[Value(data=0.9371049752278549), Value(data=-0.9721563532959269), Value(data=-0.9214628391597094), Value(data=0.9561782145156057)]\n",
      "66 {'loss': 0.012819487318763943}\n",
      "[Value(data=0.9376049844378198), Value(data=-0.972384233332364), Value(data=-0.9221242297771439), Value(data=0.9565654706018069)]\n",
      "67 {'loss': 0.012606962467491606}\n",
      "[Value(data=0.9380936850312096), Value(data=-0.9726068125643705), Value(data=-0.9227701638362423), Value(data=0.9569433149648509)]\n",
      "68 {'loss': 0.012401104270995498}\n",
      "[Value(data=0.938571491447218), Value(data=-0.972824290146504), Value(data=-0.9234012225238425), Value(data=0.957312113404829)]\n",
      "69 {'loss': 0.01220160924186469}\n",
      "[Value(data=0.9390387973237743), Value(data=-0.9730368550069465), Value(data=-0.924017957194902), Value(data=0.9576722123888138)]\n",
      "70 {'loss': 0.01200819185254173}\n",
      "[Value(data=0.9394959768143442), Value(data=-0.9732446865088811), Value(data=-0.9246208913002698), Value(data=0.9580239403337195)]\n",
      "71 {'loss': 0.011820583235131311}\n",
      "[Value(data=0.9399433858046273), Value(data=-0.9734479550605492), Value(data=-0.9252105221650304), Value(data=0.9583676087872627)]\n",
      "72 {'loss': 0.011638529991996271}\n",
      "[Value(data=0.9403813630379995), Value(data=-0.9736468226786239), Value(data=-0.925787322630868), Value(data=0.9587035135164104)]\n",
      "73 {'loss': 0.011461793106322879}\n",
      "[Value(data=0.9408102311576525), Value(data=-0.973841443509042), Value(data=-0.9263517425745353), Value(data=0.9590319355117202)]\n",
      "74 {'loss': 0.011290146943024538}\n",
      "[Value(data=0.9412302976726059), Value(data=-0.9740319643090312), Value(data=-0.9269042103132821), Value(data=0.9593531419151133)]\n",
      "75 {'loss': 0.011123378331395758}\n",
      "[Value(data=0.9416418558540566), Value(data=-0.9742185248936919), Value(data=-0.9274451339070299), Value(data=0.9596673868778537)]\n",
      "76 {'loss': 0.010961285721845451}\n",
      "[Value(data=0.9420451855679097), Value(data=-0.9744012585501624), Value(data=-0.9279749023661054), Value(data=0.9599749123548268)]\n",
      "77 {'loss': 0.010803678409849509}\n",
      "[Value(data=0.9424405540487798), Value(data=-0.9745802924221061), Value(data=-0.9284938867725006), Value(data=0.9602759488406084)]\n",
      "78 {'loss': 0.010650375820975009}\n",
      "[Value(data=0.9428282166202484), Value(data=-0.9747557478669895), Value(data=-0.9290024413218559), Value(data=0.9605707160522764)]\n",
      "79 {'loss': 0.010501206851462969}\n",
      "[Value(data=0.943208417365723), Value(data=-0.9749277407883948), Value(data=-0.9295009042926881), Value(data=0.9608594235634401)]\n",
      "80 {'loss': 0.010356009259414746}\n",
      "[Value(data=0.9435813897538418), Value(data=-0.9750963819453942), Value(data=-0.9299895989487701), Value(data=0.9611422713935357)]\n",
      "81 {'loss': 0.01021462910212529}\n",
      "[Value(data=0.9439473572220082), Value(data=-0.9752617772408276), Value(data=-0.9304688343800298), Value(data=0.961419450556053)]\n",
      "82 {'loss': 0.010076920215548154}\n",
      "[Value(data=0.9443065337213224), Value(data=-0.9754240279901609), Value(data=-0.9309389062868387), Value(data=0.9616911435690219)]\n",
      "83 {'loss': 0.009942743732269924}\n",
      "[Value(data=0.9446591242258817), Value(data=-0.9755832311724423), Value(data=-0.9314000977121285), Value(data=0.9619575249307732)]\n",
      "84 {'loss': 0.009811967634723043}\n",
      "[Value(data=0.9450053252091647), Value(data=-0.9757394796647504), Value(data=-0.9318526797253744), Value(data=0.9622187615637251)]\n",
      "85 {'loss': 0.009684466340677845}\n",
      "[Value(data=0.9453453250899784), Value(data=-0.9758928624613925), Value(data=-0.9322969120621281), Value(data=0.9624750132286874)]\n",
      "86 {'loss': 0.009560120318335889}\n",
      "[Value(data=0.9456793046502335), Value(data=-0.9760434648790137), Value(data=-0.932733043722467), Value(data=0.9627264329119657)]\n",
      "87 {'loss': 0.009438815728594918}\n",
      "[Value(data=0.9460074374266227), Value(data=-0.9761913687486651), Value(data=-0.933161313531429), Value(data=0.9629731671873383)]\n",
      "88 {'loss': 0.009320444092282847}\n",
      "[Value(data=0.9463298900781008), Value(data=-0.9763366525958035), Value(data=-0.9335819506642483), Value(data=0.9632153565548056)]\n",
      "89 {'loss': 0.009204901980356868}\n",
      "[Value(data=0.9466468227309109), Value(data=-0.9764793918091017), Value(data=-0.9339951751389673), Value(data=0.9634531357578444)]\n",
      "90 {'loss': 0.009092090725246738}\n",
      "[Value(data=0.9469583893027568), Value(data=-0.9766196587988801), Value(data=-0.9344011982787824), Value(data=0.9636866340807533)]\n",
      "91 {'loss': 0.008981916151683417}\n",
      "[Value(data=0.9472647378075878), Value(data=-0.9767575231459067), Value(data=-0.934800223146294), Value(data=0.9639159756275438)]\n",
      "92 {'loss': 0.008874288325500595}\n",
      "[Value(data=0.9475660106423536), Value(data=-0.9768930517412416), Value(data=-0.9351924449516485), Value(data=0.9641412795837104)]\n",
      "93 {'loss': 0.008769121319029441}\n",
      "[Value(data=0.9478623448569681), Value(data=-0.9770263089177619), Value(data=-0.9355780514364007), Value(data=0.9643626604621016)]\n",
      "94 {'loss': 0.008666332991826318}\n",
      "[Value(data=0.9481538724086327), Value(data=-0.9771573565739368), Value(data=-0.9359572232347825), Value(data=0.964580228334016)]\n",
      "95 {'loss': 0.008565844785580536}\n",
      "[Value(data=0.9484407204015745), Value(data=-0.9772862542903897), Value(data=-0.9363301342139261), Value(data=0.9647940890465593)]\n",
      "96 {'loss': 0.008467581532147724}\n",
      "[Value(data=0.9487230113131757), Value(data=-0.9774130594397378), Value(data=-0.936696951794472), Value(data=0.9650043444272096)]\n",
      "97 {'loss': 0.008371471273742303}\n",
      "[Value(data=0.9490008632073964), Value(data=-0.977537827290156), Value(data=-0.9370578372528802), Value(data=0.9652110924764711)]\n",
      "98 {'loss': 0.00827744509440312}\n",
      "[Value(data=0.9492743899363225), Value(data=-0.9776606111030918), Value(data=-0.937412946006663), Value(data=0.9654144275494213)]\n",
      "99 {'loss': 0.00818543696191867}\n",
      "[Value(data=0.9495437013306118), Value(data=-0.9777814622255063), Value(data=-0.937762427883663), Value(data=0.9656144405268996)]\n",
      "100 {'loss': 0.008095383579465473}\n",
      "[Value(data=0.9498089033795512), Value(data=-0.977900430177011), Value(data=-0.9381064273764181), Value(data=0.965811218977024)]\n",
      "101 {'loss': 0.008007224246272001}\n",
      "[Value(data=0.9500700984013858), Value(data=-0.9780175627322167), Value(data=-0.9384450838825789), Value(data=0.9660048473076738)]\n",
      "102 {'loss': 0.007920900726676653}\n",
      "[Value(data=0.9503273852045359), Value(data=-0.978132905998614), Value(data=-0.938778531932266), Value(data=0.9661954069105263)]\n",
      "103 {'loss': 0.007836357126997479}\n",
      "[Value(data=0.9505808592402688), Value(data=-0.9782465044902574), Value(data=-0.9391069014032007), Value(data=0.9663829762971933)]\n",
      "104 {'loss': 0.007753539779677101}\n",
      "[Value(data=0.9508306127473553), Value(data=-0.9783584011975275), Value(data=-0.9394303177243718), Value(data=0.9665676312279614)]\n",
      "105 {'loss': 0.007672397134207853}\n",
      "[Value(data=0.9510767348892026), Value(data=-0.9784686376532044), Value(data=-0.9397489020689539), Value(data=0.966749444833606)]\n",
      "106 {'loss': 0.007592879654380289}\n",
      "[Value(data=0.951319311883921), Value(data=-0.9785772539950882), Value(data=-0.9400627715371374), Value(data=0.9669284877307114)]\n",
      "107 {'loss': 0.007514939721433014}\n",
      "[Value(data=0.9515584271277481), Value(data=-0.9786842890253732), Value(data=-0.9403720393294895), Value(data=0.9671048281309025)]\n",
      "108 {'loss': 0.007438531542712927}\n",
      "[Value(data=0.9517941613122283), Value(data=-0.9787897802669733), Value(data=-0.9406768149114133), Value(data=0.9672785319443611)]\n",
      "109 {'loss': 0.0073636110654856585}\n",
      "[Value(data=0.9520265925355175), Value(data=-0.9788937640169817), Value(data=-0.9409772041692442), Value(data=0.9674496628779781)]\n",
      "110 {'loss': 0.007290135895560483}\n",
      "[Value(data=0.9522557964081546), Value(data=-0.9789962753974335), Value(data=-0.9412733095584752), Value(data=0.9676182825284615)]\n",
      "111 {'loss': 0.007218065220421261}\n",
      "[Value(data=0.9524818461536232), Value(data=-0.979097348403534), Value(data=-0.9415652302445792), Value(data=0.9677844504707077)]\n",
      "112 {'loss': 0.007147359736574508}\n",
      "[Value(data=0.9527048127040038), Value(data=-0.9791970159494945), Value(data=-0.9418530622368557), Value(data=0.9679482243417127)]\n",
      "113 {'loss': 0.007077981580849105}\n",
      "[Value(data=0.9529247647909942), Value(data=-0.9792953099121214), Value(data=-0.9421368985157091), Value(data=0.9681096599202887)]\n",
      "114 {'loss': 0.007009894265399298}\n",
      "[Value(data=0.9531417690325636), Value(data=-0.9793922611722795), Value(data=-0.9424168291537325), Value(data=0.968268811202829)]\n",
      "115 {'loss': 0.006943062616181292}\n",
      "[Value(data=0.9533558900154825), Value(data=-0.9794878996543592), Value(data=-0.9426929414309498), Value(data=0.9684257304753507)]\n",
      "116 {'loss': 0.006877452714689143}\n",
      "[Value(data=0.9535671903739591), Value(data=-0.9795822543638506), Value(data=-0.9429653199445471), Value(data=0.9685804683820284)]\n",
      "117 {'loss': 0.006813031842751247}\n",
      "[Value(data=0.9537757308645967), Value(data=-0.9796753534231386), Value(data=-0.9432340467133993), Value(data=0.9687330739904179)]\n",
      "118 {'loss': 0.0067497684302017455}\n",
      "[Value(data=0.9539815704378745), Value(data=-0.9797672241056132), Value(data=-0.9434992012776785), Value(data=0.9688835948535567)]\n",
      "119 {'loss': 0.006687632005254678}\n",
      "[Value(data=0.9541847663063376), Value(data=-0.9798578928681886), Value(data=-0.9437608607938215), Value(data=0.9690320770691169)]\n",
      "120 {'loss': 0.006626593147419306}\n",
      "[Value(data=0.9543853740096772), Value(data=-0.9799473853823167), Value(data=-0.9440191001251005), Value(data=0.9691785653357706)]\n",
      "121 {'loss': 0.0065666234428072455}\n",
      "[Value(data=0.9545834474768622), Value(data=-0.9800357265635808), Value(data=-0.9442739919280405), Value(data=0.9693231030069268)]\n",
      "122 {'loss': 0.006507695441690764}\n",
      "[Value(data=0.9547790390854843), Value(data=-0.9801229405999385), Value(data=-0.9445256067349052), Value(data=0.9694657321419756)]\n",
      "123 {'loss': 0.006449782618181707}\n",
      "[Value(data=0.9549721997184568), Value(data=-0.9802090509786929), Value(data=-0.9447740130324579), Value(data=0.9696064935551815)]\n",
      "124 {'loss': 0.006392859331908872}\n",
      "[Value(data=0.9551629788182091), Value(data=-0.9802940805122536), Value(data=-0.9450192773371969), Value(data=0.9697454268623471)]\n",
      "125 {'loss': 0.006336900791579563}\n",
      "[Value(data=0.955351424438505), Value(data=-0.9803780513627556), Value(data=-0.9452614642672489), Value(data=0.9698825705253689)]\n",
      "126 {'loss': 0.006281883020318242}\n",
      "[Value(data=0.9555375832940073), Value(data=-0.9804609850655894), Value(data=-0.9455006366110935), Value(data=0.9700179618947935)]\n",
      "127 {'loss': 0.006227782822682594}\n",
      "[Value(data=0.955721500807702), Value(data=-0.9805429025519072), Value(data=-0.9457368553932819), Value(data=0.9701516372504821)]\n",
      "128 {'loss': 0.006174577753263316}\n",
      "[Value(data=0.9559032211562919), Value(data=-0.9806238241701482), Value(data=-0.9459701799373051), Value(data=0.9702836318404793)]\n",
      "129 {'loss': 0.006122246086779599}\n",
      "[Value(data=0.9560827873136603), Value(data=-0.9807037697066374), Value(data=-0.9462006679257543), Value(data=0.9704139799181792)]\n",
      "130 {'loss': 0.006070766789588547}\n",
      "[Value(data=0.9562602410925009), Value(data=-0.9807827584053079), Value(data=-0.9464283754579115), Value(data=0.9705427147778772)]\n",
      "131 {'loss': 0.0060201194925309075}\n",
      "[Value(data=0.9564356231842059), Value(data=-0.9808608089865819), Value(data=-0.9466533571048968), Value(data=0.9706698687887877)]\n",
      "132 {'loss': 0.00597028446504119}\n",
      "[Value(data=0.9566089731970953), Value(data=-0.9809379396654605), Value(data=-0.9468756659624953), Value(data=0.9707954734276057)]\n",
      "133 {'loss': 0.005921242590454085}\n",
      "[Value(data=0.9567803296930689), Value(data=-0.9810141681688562), Value(data=-0.9470953537017777), Value(data=0.9709195593096865)]\n",
      "134 {'loss': 0.0058729753424431414}\n",
      "[Value(data=0.9569497302227596), Value(data=-0.9810895117522076), Value(data=-0.9473124706176211), Value(data=0.9710421562189089)]\n",
      "135 {'loss': 0.005825464762532183}\n",
      "[Value(data=0.9571172113592552), Value(data=-0.9811639872154096), Value(data=-0.9475270656752329), Value(data=0.9711632931362901)]\n",
      "136 {'loss': 0.005778693438622893}\n",
      "[Value(data=0.9572828087304615), Value(data=-0.9812376109180927), Value(data=-0.9477391865547736), Value(data=0.9712829982674114)]\n",
      "137 {'loss': 0.005732644484485466}\n",
      "[Value(data=0.9574465570501673), Value(data=-0.9813103987942835), Value(data=-0.9479488796941699), Value(data=0.9714012990687128)]\n",
      "138 {'loss': 0.005687301520162595}\n",
      "[Value(data=0.957608490147875), Value(data=-0.9813823663664727), Value(data=-0.9481561903302036), Value(data=0.9715182222727117)]\n",
      "139 {'loss': 0.005642648653239793}\n",
      "[Value(data=0.9577686409974516), Value(data=-0.9814535287591238), Value(data=-0.9483611625379567), Value(data=0.9716337939121961)]\n",
      "140 {'loss': 0.005598670460937866}\n",
      "[Value(data=0.9579270417446576), Value(data=-0.9815239007116429), Value(data=-0.948563839268691), Value(data=0.9717480393434414)]\n",
      "141 {'loss': 0.0055553519729858}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Value(data=0.9580837237336022), Value(data=-0.9815934965908375), Value(data=-0.9487642623862351), Value(data=0.9718609832684983)]\n",
      "142 {'loss': 0.005512678655234787}\n",
      "[Value(data=0.958238717532177), Value(data=-0.9816623304028895), Value(data=-0.9489624727019451), Value(data=0.9719726497565923)]\n",
      "143 {'loss': 0.005470636393976433}\n",
      "[Value(data=0.9583920529565114), Value(data=-0.9817304158048604), Value(data=-0.9491585100083086), Value(data=0.9720830622646784)]\n",
      "144 {'loss': 0.005429211480930117}\n",
      "[Value(data=0.9585437590944962), Value(data=-0.9817977661157545), Value(data=-0.949352413111249), Value(data=0.9721922436571909)]\n",
      "145 {'loss': 0.005388390598866566}\n",
      "[Value(data=0.9586938643284154), Value(data=-0.9818643943271559), Value(data=-0.9495442198611914), Value(data=0.9723002162250217)]\n",
      "146 {'loss': 0.005348160807836589}\n",
      "[Value(data=0.9588423963567265), Value(data=-0.9819303131134627), Value(data=-0.9497339671829487), Value(data=0.9724070017037654)]\n",
      "147 {'loss': 0.005308509531975186}\n",
      "[Value(data=0.9589893822150272), Value(data=-0.9819955348417316), Value(data=-0.9499216911044714), Value(data=0.972512621291263)]\n",
      "148 {'loss': 0.005269424546853931}\n",
      "[Value(data=0.9591348482962426), Value(data=-0.9820600715811556), Value(data=-0.9501074267845234), Value(data=0.9726170956644767)]\n",
      "149 {'loss': 0.005230893967354475}\n",
      "[Value(data=0.9592788203700693), Value(data=-0.9821239351121859), Value(data=-0.9502912085393199), Value(data=0.9727204449957242)]\n",
      "150 {'loss': 0.005192906236039116}\n",
      "[Value(data=0.9594213236017053), Value(data=-0.9821871369353159), Value(data=-0.9504730698681804), Value(data=0.9728226889683015)]\n",
      "151 {'loss': 0.005155450111994532}\n",
      "[Value(data=0.9595623825698999), Value(data=-0.9822496882795428), Value(data=-0.9506530434782365), Value(data=0.9729238467915224)]\n",
      "152 {'loss': 0.005118514660126298}\n",
      "[Value(data=0.9597020212843494), Value(data=-0.9823116001105185), Value(data=-0.9508311613082354), Value(data=0.9730239372151982)]\n",
      "153 {'loss': 0.005082089240883568}\n",
      "[Value(data=0.9598402632024694), Value(data=-0.9823728831384061), Value(data=-0.9510074545514771), Value(data=0.9731229785435832)]\n",
      "154 {'loss': 0.005046163500393496}\n",
      "[Value(data=0.9599771312455658), Value(data=-0.982433547825449), Value(data=-0.9511819536779252), Value(data=0.9732209886488087)]\n",
      "155 {'loss': 0.0050107273609869205}\n",
      "[Value(data=0.9601126478144351), Value(data=-0.9824936043932738), Value(data=-0.9513546884555227), Value(data=0.9733179849838274)]\n",
      "156 {'loss': 0.004975771012097009}\n",
      "[Value(data=0.9602468348044121), Value(data=-0.9825530628299274), Value(data=-0.9515256879707478), Value(data=0.9734139845948896)]\n",
      "157 {'loss': 0.00494128490151424}\n",
      "[Value(data=0.9603797136198932), Value(data=-0.9826119328966695), Value(data=-0.9516949806484415), Value(data=0.9735090041335699)]\n",
      "158 {'loss': 0.004907259726981263}\n",
      "[Value(data=0.9605113051883514), Value(data=-0.9826702241345221), Value(data=-0.9518625942709389), Value(data=0.9736030598683645)]\n",
      "159 {'loss': 0.004873686428112621}\n",
      "[Value(data=0.960641629973869), Value(data=-0.9827279458705929), Value(data=-0.9520285559965267), Value(data=0.9736961676958766)]\n",
      "160 {'loss': 0.004840556178624833}\n",
      "[Value(data=0.9607707079902033), Value(data=-0.9827851072241772), Value(data=-0.9521928923772639), Value(data=0.9737883431516066)]\n",
      "161 {'loss': 0.004807860378862781}\n",
      "[Value(data=0.9608985588134062), Value(data=-0.9828417171126497), Value(data=-0.9523556293761836), Value(data=0.973879601420364)]\n",
      "162 {'loss': 0.004775590648609622}\n",
      "[Value(data=0.9610252015940169), Value(data=-0.9828977842571539), Value(data=-0.9525167923839043), Value(data=0.9739699573463171)]\n",
      "163 {'loss': 0.004743738820167673}\n",
      "[Value(data=0.9611506550688401), Value(data=-0.982953317188097), Value(data=-0.9526764062346752), Value(data=0.9740594254426928)]\n",
      "164 {'loss': 0.004712296931698573}\n",
      "[Value(data=0.9612749375723317), Value(data=-0.9830083242504588), Value(data=-0.9528344952218767), Value(data=0.9741480199011442)]\n",
      "165 {'loss': 0.0046812572208111605}\n",
      "[Value(data=0.9613980670476034), Value(data=-0.9830628136089218), Value(data=-0.952991083112997), Value(data=0.9742357546007968)]\n",
      "166 {'loss': 0.004650612118386967}\n",
      "[Value(data=0.9615200610570632), Value(data=-0.9831167932528291), Value(data=-0.953146193164109), Value(data=0.9743226431169868)]\n",
      "167 {'loss': 0.004620354242632473}\n",
      "[Value(data=0.9616409367927042), Value(data=-0.9831702710009765), Value(data=-0.9532998481338617), Value(data=0.9744086987297043)]\n",
      "168 {'loss': 0.004590476393349303}\n",
      "[Value(data=0.961760711086058), Value(data=-0.9832232545062481), Value(data=-0.9534520702970117), Value(data=0.9744939344317525)]\n",
      "169 {'loss': 0.004560971546412131}\n",
      "[Value(data=0.9618794004178218), Value(data=-0.9832757512600968), Value(data=-0.9536028814575054), Value(data=0.9745783629366347)]\n",
      "170 {'loss': 0.004531832848446683}\n",
      "[Value(data=0.9619970209271764), Value(data=-0.9833277685968785), Value(data=-0.9537523029611361), Value(data=0.9746619966861786)]\n",
      "171 {'loss': 0.00450305361169846}\n",
      "[Value(data=0.9621135884208014), Value(data=-0.9833793136980482), Value(data=-0.9539003557077866), Value(data=0.9747448478579098)]\n",
      "172 {'loss': 0.004474627309085042}\n",
      "[Value(data=0.9622291183816045), Value(data=-0.9834303935962159), Value(data=-0.9540470601632782), Value(data=0.9748269283721823)]\n",
      "173 {'loss': 0.004446547569423779}\n",
      "[Value(data=0.9623436259771705), Value(data=-0.9834810151790763), Value(data=-0.9541924363708352), Value(data=0.974908249899077)]\n",
      "174 {'loss': 0.004418808172828292}\n",
      "[Value(data=0.9624571260679452), Value(data=-0.9835311851932093), Value(data=-0.9543365039621861), Value(data=0.9749888238650762)]\n",
      "175 {'loss': 0.00439140304626616}\n",
      "[Value(data=0.9625696332151605), Value(data=-0.9835809102477626), Value(data=-0.9544792821683091), Value(data=0.9750686614595223)]\n",
      "176 {'loss': 0.004364326259271967}\n",
      "[Value(data=0.9626811616885117), Value(data=-0.9836301968180158), Value(data=-0.9546207898298396), Value(data=0.9751477736408701)]\n",
      "177 {'loss': 0.00433757201980893}\n",
      "[Value(data=0.9627917254735959), Value(data=-0.9836790512488334), Value(data=-0.9547610454071483), Value(data=0.9752261711427392)]\n",
      "178 {'loss': 0.004311134670273398}\n",
      "[Value(data=0.9629013382791214), Value(data=-0.9837274797580098), Value(data=-0.9549000669901071), Value(data=0.9753038644797742)]\n",
      "179 {'loss': 0.00428500868363635}\n",
      "[Value(data=0.9630100135438929), Value(data=-0.9837754884395108), Value(data=-0.9550378723075476), Value(data=0.9753808639533211)]\n",
      "180 {'loss': 0.004259188659716715}\n",
      "[Value(data=0.9631177644435859), Value(data=-0.9838230832666132), Value(data=-0.9551744787364296), Value(data=0.9754571796569242)]\n",
      "181 {'loss': 0.004233669321581046}\n",
      "[Value(data=0.9632246038973121), Value(data=-0.9838702700949498), Value(data=-0.9553099033107278), Value(data=0.9755328214816528)]\n",
      "182 {'loss': 0.0042084455120646284}\n",
      "[Value(data=0.9633305445739886), Value(data=-0.9839170546654606), Value(data=-0.9554441627300453), Value(data=0.9756077991212622)]\n",
      "183 {'loss': 0.004183512190409403}\n",
      "[Value(data=0.9634355988985132), Value(data=-0.9839634426072543), Value(data=-0.9555772733679643), Value(data=0.9756821220771955)]\n",
      "184 {'loss': 0.004158864429014236}\n",
      "[Value(data=0.9635397790577565), Value(data=-0.9840094394403821), Value(data=-0.9557092512801478), Value(data=0.975755799663432)]\n",
      "185 {'loss': 0.004134497410292755}\n",
      "[Value(data=0.9636430970063745), Value(data=-0.9840550505785307), Value(data=-0.9558401122121931), Value(data=0.9758288410111876)]\n",
      "186 {'loss': 0.00411040642363525}\n",
      "[Value(data=0.9637455644724496), Value(data=-0.984100281331632), Value(data=-0.9559698716072522), Value(data=0.975901255073473)]\n",
      "187 {'loss': 0.004086586862470221}\n",
      "[Value(data=0.9638471929629651), Value(data=-0.984145136908397), Value(data=-0.9560985446134266), Value(data=0.9759730506295133)]\n",
      "188 {'loss': 0.004063034221421784}\n",
      "[Value(data=0.9639479937691191), Value(data=-0.9841896224187733), Value(data=-0.9562261460909401), Value(data=0.9760442362890359)]\n",
      "189 {'loss': 0.00403974409355969}\n",
      "[Value(data=0.9640479779714842), Value(data=-0.9842337428763325), Value(data=-0.9563526906191033), Value(data=0.9761148204964305)]\n",
      "190 {'loss': 0.004016712167737927}\n",
      "[Value(data=0.9641471564450166), Value(data=-0.9842775032005837), Value(data=-0.9564781925030712), Value(data=0.976184811534784)]\n",
      "191 {'loss': 0.003993934226019257}\n",
      "[Value(data=0.9642455398639211), Value(data=-0.9843209082192241), Value(data=-0.9566026657804058), Value(data=0.9762542175297982)]\n",
      "192 {'loss': 0.003971406141181752}\n",
      "[Value(data=0.964343138706377), Value(data=-0.9843639626703223), Value(data=-0.9567261242274485), Value(data=0.9763230464535907)]\n",
      "193 {'loss': 0.003949123874304786}\n",
      "[Value(data=0.9644399632591277), Value(data=-0.9844066712044364), Value(data=-0.9568485813655059), Value(data=0.9763913061283856)]\n",
      "194 {'loss': 0.003927083472431707}\n",
      "[Value(data=0.9645360236219414), Value(data=-0.9844490383866764), Value(data=-0.9569700504668617), Value(data=0.9764590042300968)]\n",
      "195 {'loss': 0.003905281066305597}\n",
      "[Value(data=0.9646313297119447), Value(data=-0.9844910686987031), Value(data=-0.9570905445606144), Value(data=0.9765261482918066)]\n",
      "196 {'loss': 0.0038837128681763907}\n",
      "[Value(data=0.9647258912678344), Value(data=-0.984532766540673), Value(data=-0.9572100764383495), Value(data=0.9765927457071458)]\n",
      "197 {'loss': 0.0038623751696761975}\n",
      "[Value(data=0.9648197178539725), Value(data=-0.9845741362331265), Value(data=-0.9573286586596532), Value(data=0.9766588037335753)]\n",
      "198 {'loss': 0.0038412643397603917}\n",
      "[Value(data=0.9649128188643653), Value(data=-0.984615182018825), Value(data=-0.9574463035574675), Value(data=0.9767243294955753)]\n",
      "199 {'loss': 0.0038203768227124714}\n"
     ]
    }
   ],
   "source": [
    "# training the Model multiple times\n",
    "\n",
    "iterations_training = 200 # iterations_training\n",
    "\n",
    "print(\"Expected result:\\n\")\n",
    "print(ys)\n",
    "print(\"---------------------------------------\\n\")\n",
    "for k in range(iterations_training):\n",
    "    # Forward pass\n",
    "    ypred = [n(x) for x in xs] # predicted results from MLP for each group of inputs\n",
    "    loss = sum([(yout - ygt)**2 for ygt, yout in zip(ys, ypred)])\n",
    "    # zero grad to flush previous gradients\n",
    "    for p in n.parameters():\n",
    "        p.grad = 0.0\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    # Update\n",
    "    for p in n.parameters():\n",
    "        p.data += -0.05 * p.grad\n",
    "    # Show status\n",
    "    print(ypred)\n",
    "    print(k, {\"loss\": loss.data})\n",
    "    \n",
    "# if the step is too large and goes over the point where loss is close to zero, the loss will change values into something that will not make sense\n",
    "# to get closer to zero we could make the step size bigger with the risk of going over the zero loss point or we can do more training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b423183e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
