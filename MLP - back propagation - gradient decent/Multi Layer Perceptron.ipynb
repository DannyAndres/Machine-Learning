{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18267e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c709f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value:\n",
    "  \n",
    "  def __init__(self, data, _children=(), _op='', label=''):\n",
    "    self.data = data\n",
    "    self.grad = 0.0\n",
    "    self._backward = lambda: None\n",
    "    self._prev = set(_children)\n",
    "    self._op = _op\n",
    "    self.label = label\n",
    "\n",
    "  def __repr__(self):\n",
    "    return f\"Value(data={self.data})\"\n",
    "  \n",
    "  def __add__(self, other):\n",
    "    other = other if isinstance(other, Value) else Value(other)\n",
    "    out = Value(self.data + other.data, (self, other), '+')\n",
    "    \n",
    "    def _backward():\n",
    "      self.grad += 1.0 * out.grad\n",
    "      other.grad += 1.0 * out.grad\n",
    "    out._backward = _backward\n",
    "    \n",
    "    return out\n",
    "\n",
    "  def __mul__(self, other):\n",
    "    other = other if isinstance(other, Value) else Value(other)\n",
    "    out = Value(self.data * other.data, (self, other), '*')\n",
    "    \n",
    "    def _backward():\n",
    "      self.grad += other.data * out.grad\n",
    "      other.grad += self.data * out.grad\n",
    "    out._backward = _backward\n",
    "      \n",
    "    return out\n",
    "  \n",
    "  def __pow__(self, other):\n",
    "    assert isinstance(other, (int, float)), \"only supporting int/float powers for now\"\n",
    "    out = Value(self.data**other, (self,), f'**{other}')\n",
    "\n",
    "    def _backward():\n",
    "        self.grad += other * (self.data ** (other - 1)) * out.grad\n",
    "    out._backward = _backward\n",
    "\n",
    "    return out\n",
    "  \n",
    "  def __rmul__(self, other): # other * self\n",
    "    return self * other\n",
    "\n",
    "  def __truediv__(self, other): # self / other\n",
    "    return self * other**-1\n",
    "\n",
    "  def __neg__(self): # -self\n",
    "    return self * -1\n",
    "\n",
    "  def __sub__(self, other): # self - other\n",
    "    return self + (-other)\n",
    "\n",
    "  def __radd__(self, other): # other + self\n",
    "    return self + other\n",
    "\n",
    "  def tanh(self):\n",
    "    x = self.data\n",
    "    t = (math.exp(2*x) - 1)/(math.exp(2*x) + 1)\n",
    "    out = Value(t, (self, ), 'tanh')\n",
    "    \n",
    "    def _backward():\n",
    "      self.grad += (1 - t**2) * out.grad\n",
    "    out._backward = _backward\n",
    "    \n",
    "    return out\n",
    "  \n",
    "  def exp(self):\n",
    "    x = self.data\n",
    "    out = Value(math.exp(x), (self, ), 'exp')\n",
    "    \n",
    "    def _backward():\n",
    "      self.grad += out.data * out.grad # NOTE: in the video I incorrectly used = instead of +=. Fixed here.\n",
    "    out._backward = _backward\n",
    "    \n",
    "    return out\n",
    "  \n",
    "  \n",
    "  def backward(self):\n",
    "    \n",
    "    topo = []\n",
    "    visited = set()\n",
    "    def build_topo(v):\n",
    "      if v not in visited:\n",
    "        visited.add(v)\n",
    "        for child in v._prev:\n",
    "          build_topo(child)\n",
    "        topo.append(v)\n",
    "    build_topo(self)\n",
    "    \n",
    "    self.grad = 1.0\n",
    "    for node in reversed(topo):\n",
    "      node._backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71afbca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "  \n",
    "  def __init__(self, nin):\n",
    "    self.w = [Value(random.uniform(-1,1)) for _ in range(nin)]\n",
    "    self.b = Value(random.uniform(-1,1))\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    # w * x + b\n",
    "    act = sum((wi*xi for wi, xi in zip(self.w, x)), self.b)\n",
    "    out = act.tanh()\n",
    "    return out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return self.w + [self.b]\n",
    "\n",
    "class Layer:\n",
    "  \n",
    "  def __init__(self, nin, nout):\n",
    "    self.neurons = [Neuron(nin) for _ in range(nout)]\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    outs = [n(x) for n in self.neurons]\n",
    "    return outs[0] if len(outs) == 1 else outs\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [p for neuron in self.neurons for p in neuron.parameters()]\n",
    "\n",
    "class MLP:\n",
    "  \n",
    "  def __init__(self, nin, nouts):\n",
    "    sz = [nin] + nouts\n",
    "    self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    for layer in self.layers:\n",
    "      x = layer(x)\n",
    "    return x\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3b6dfb53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(data=-0.3385994072604859)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1\n",
    "x = [2.0, 3.0, -1.0] # inputs\n",
    "n = MLP(3, [4, 4, 1]) # MLP(inputs, layers=(4 node layer, 4 node layer, 1 node layer - output))\n",
    "n(x) # passing the inputs to the Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "fc4b1651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Value(data=-0.3385994072604859),\n",
       " Value(data=-0.504481117999009),\n",
       " Value(data=-0.49052826352576057),\n",
       " Value(data=-0.37375254461563556)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2\n",
    "xs = [\n",
    "  [2.0, 3.0, -1.0], # expected result = 1.0\n",
    "  [3.0, -1.0, 0.5], # expected result = -1.0\n",
    "  [0.5, 1.0, 1.0], # expected result = -1.0\n",
    "  [1.0, 1.0, -1.0], # expected result = 1.0\n",
    "] # list of groups of inputs\n",
    "ys = [1.0, -1.0, -1.0, 1.0] # desired targets for each group of inputs\n",
    "\n",
    "ypred = [n(x) for x in xs] # predicted results from MLP for each group of inputs\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "096b4502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(data=4.184144839641647)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating Loss value for example 2 - using square function for loss\n",
    "list_of_losses = [(yout - ygt)**2 for ygt, yout in zip(ys, ypred)]\n",
    "# zip ex: a = [1,2,3] b = [a,b,c] zip(a,b) = [[1,a],[2,b],[3,c]]\n",
    "# ygt means Y ground truth which is the expected result\n",
    "\n",
    "list_of_losses\n",
    "# returned a list of losses for each group of inputs\n",
    "\n",
    "loss = sum(list_of_losses)\n",
    "# total loss = the sum of all losses of expected results\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "24ffaa32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24024189042170316"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating grade of nodes with derivative \n",
    "\n",
    "# because ypred is a list of output nodes of the MLP and we apply - and ** to those nodes which are instances of Value that has a -,** method\n",
    "# it means that the result of list of losses and loss itself are Value objects\n",
    "\n",
    "# losses = loss of ys0 + loss of ys1 + loss of ys2 + loss of ys3\n",
    "# loss of ys0 = object MLP + loss function -> loss function = (ys0 - ygt0)**2 -> object MLP is a graph with the output node ys0\n",
    "\n",
    "# doing backward() on loss will spread the gradient (derivate) to the loss function but also to the MLP\n",
    "# due to that we have, 1) how much the nodes affect the loss function, but also, 2) how much the nodes affect the output node ys0\n",
    "\n",
    "loss.backward() # always do one calculation per MLP creation because derivates add up and can acumulate\n",
    "n.layers[0].neurons[0].w[0].grad\n",
    "# how much this affects the loss or the output results\n",
    "# first layer, first neuron, first weight (one weight per input on a neuron, each neuron has 3 inputs), gradient derivative\n",
    "\n",
    "# the goal is to get a prediction or results as close as the ygt y ground truth value (expected result) to reduce loss as close to zero we can\n",
    "# if we make a Weight with a possitive gradient higher we will get a higher output\n",
    "# if we make a Weight with a negative gradient lower we will get a lower output\n",
    "# if the output is closer to the expected result we will get a lower loss\n",
    "# if the output is farther from the expected result we will get a higher loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1329a473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Value(data=-0.5230288503263478),\n",
       " Value(data=0.10290939418529921),\n",
       " Value(data=0.6149691881406345),\n",
       " Value(data=-0.5650960656513733),\n",
       " Value(data=0.0055766926217823976),\n",
       " Value(data=0.9987392215334487),\n",
       " Value(data=-0.3846799299051995),\n",
       " Value(data=-0.2260773625343271),\n",
       " Value(data=-0.6476436149471521),\n",
       " Value(data=-0.2139538772240397),\n",
       " Value(data=-0.5427440826293402),\n",
       " Value(data=-0.36273715859179645),\n",
       " Value(data=-0.018570376978292558),\n",
       " Value(data=-0.31023969845546606),\n",
       " Value(data=0.8746668788508833),\n",
       " Value(data=-0.8779532305726485),\n",
       " Value(data=-0.486705861136824),\n",
       " Value(data=0.4544363889284224),\n",
       " Value(data=0.27186030797596206),\n",
       " Value(data=-0.3560371383203891),\n",
       " Value(data=0.7894453494722551),\n",
       " Value(data=-0.2704499405374148),\n",
       " Value(data=0.5545171215117954),\n",
       " Value(data=-0.63688475044623),\n",
       " Value(data=0.6256998926971364),\n",
       " Value(data=-0.9061911247777024),\n",
       " Value(data=0.3423366933167886),\n",
       " Value(data=0.9729720044670649),\n",
       " Value(data=-0.10316811212932286),\n",
       " Value(data=0.6997587202142392),\n",
       " Value(data=-0.44103620496750184),\n",
       " Value(data=-0.6928299438846384),\n",
       " Value(data=0.24083296225230422),\n",
       " Value(data=0.9666903887539546),\n",
       " Value(data=0.065762617452372),\n",
       " Value(data=-0.6470263591841015),\n",
       " Value(data=-0.3493797533308034),\n",
       " Value(data=0.5833210013964265),\n",
       " Value(data=-0.08245201606895969),\n",
       " Value(data=0.5961711570299459),\n",
       " Value(data=0.38175311455915706)]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting all the parameters of the MLP - values we can interact with to change the output (weights and biases)\n",
    "\n",
    "n.parameters()\n",
    "# node1w1,node1w2,node1w3,node1bias,node2w1,node2w2,node2w3,node2bias, ... \n",
    "# has all the objects inside we can modify them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "bba70b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'g': 0.24024189042170316, 'w': -0.5230288503263478}\n"
     ]
    }
   ],
   "source": [
    "# Gradient decent\n",
    "\n",
    "# we modify each parameter by a tiny STEP size in the direction of the gradient\n",
    "\n",
    "# following the direction can get us closer to the loss\n",
    "print({\"g\": n.layers[0].neurons[0].w[0].grad, \"w\": n.layers[0].neurons[0].w[0].data})\n",
    "# 1) if grad is negative means that making W bigger the lost will be lower\n",
    "# 2) if grad is possitive means that making W smaller the lost will be lower\n",
    "\n",
    "# if the amount to add is (step * grad) means:\n",
    "# 1) if grad is negative, W must get bigger -> (step(negative) * grad(negative)) -> step must be negative to cancel the grad\n",
    "# 2) if grad is possitive, W must get smaller -> (step(negative) * grad(possitive)) -> step must be negative to take out the grad\n",
    "\n",
    "# the previous is \"following the direction of the gradient\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b3bc782c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5254312692305648"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing the weights\n",
    "stepSign = -1\n",
    "\n",
    "# update\n",
    "for p in n.parameters():\n",
    "    p.data += stepSign * 0.01 * p.grad\n",
    "    \n",
    "n.layers[0].neurons[0].w[0].data\n",
    "# new weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8a176f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Value(data=-0.18278168566528033), Value(data=-0.437208144315173), Value(data=-0.41035056814230064), Value(data=-0.22528344305775064)]\n",
      "{'old loss': Value(data=4.184144839641647), 'new loss': Value(data=3.564713157091937)}\n"
     ]
    }
   ],
   "source": [
    "ypred = [n(x) for x in xs] # predicted results from MLP for each group of inputs\n",
    "print(ypred)\n",
    "# Calculating Loss after changing weights\n",
    "new_loss = sum([(yout - ygt)**2 for ygt, yout in zip(ys, ypred)])\n",
    "print({\"old loss\": loss, \"new loss\": new_loss})\n",
    "loss = new_loss\n",
    "loss.backward() # backward pass -> recalculate gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2f4dd5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected result:\n",
      "\n",
      "[1.0, -1.0, -1.0, 1.0]\n",
      "---------------------------------------\n",
      "\n",
      "[Value(data=-0.18278168566528033), Value(data=-0.437208144315173), Value(data=-0.41035056814230064), Value(data=-0.22528344305775064)]\n",
      "0 {'loss': 3.564713157091937}\n",
      "[Value(data=-0.030499560862332614), Value(data=-0.3814262661487062), Value(data=-0.338935144060703), Value(data=-0.07755008437008608)]\n",
      "1 {'loss': 3.042683737232215}\n",
      "[Value(data=0.09860905341016384), Value(data=-0.3459805544412464), Value(data=-0.28702566980048577), Value(data=0.050181871423075106)]\n",
      "2 {'loss': 2.6507339466599182}\n",
      "[Value(data=0.19864568430294613), Value(data=-0.33192516572058717), Value(data=-0.25763651879685406), Value(data=0.15082125238572305)]\n",
      "3 {'loss': 2.3607008071075635}\n",
      "[Value(data=0.27428832966973543), Value(data=-0.33465767430840987), Value(data=-0.24742676944705866), Value(data=0.22776579004884379)]\n",
      "4 {'loss': 2.132049981174014}\n",
      "[Value(data=0.33265443146503304), Value(data=-0.3484709703248173), Value(data=-0.25123363386382375), Value(data=0.28740754781399575)]\n",
      "5 {'loss': 1.9382792583219808}\n",
      "[Value(data=0.37947743362036107), Value(data=-0.36876720656781053), Value(data=-0.2645324459954356), Value(data=0.3351885093859575)]\n",
      "6 {'loss': 1.7663899359365007}\n",
      "[Value(data=0.41859716957323717), Value(data=-0.39237124104965515), Value(data=-0.28395024751355213), Value(data=0.3748776085812381)]\n",
      "7 {'loss': 1.6107472122208024}\n",
      "[Value(data=0.4524144857528688), Value(data=-0.41723728232593793), Value(data=-0.30709828923454235), Value(data=0.40890105739750215)]\n",
      "8 {'loss': 1.4689730212516425}\n",
      "[Value(data=0.4823937220076587), Value(data=-0.44210293772270903), Value(data=-0.33230655063467013), Value(data=0.43878642849731286)]\n",
      "9 {'loss': 1.3399406062788906}\n",
      "[Value(data=0.5094264302023823), Value(data=-0.4662221845658875), Value(data=-0.35841013354746815), Value(data=0.46549947740377484)]\n",
      "10 {'loss': 1.222909549023807}\n",
      "[Value(data=0.5340653199375957), Value(data=-0.48918143832619626), Value(data=-0.3846000899191191), Value(data=0.48966508257277386)]\n",
      "11 {'loss': 1.1171895063083586}\n",
      "[Value(data=0.5566672004065144), Value(data=-0.5107778876949594), Value(data=-0.4103223397843593), Value(data=0.5117037774105959)]\n",
      "12 {'loss': 1.022035190316077}\n",
      "[Value(data=0.5774775020708761), Value(data=-0.5309402006276204), Value(data=-0.4352081190733546), Value(data=0.5319134884523198)]\n",
      "13 {'loss': 0.9366372076970582}\n",
      "[Value(data=0.5966788434667798), Value(data=-0.5496771054635359), Value(data=-0.45902444766634426), Value(data=0.5505175298861009)]\n",
      "14 {'loss': 0.8601477038133897}\n",
      "[Value(data=0.6144181193902126), Value(data=-0.5670441419103517), Value(data=-0.48163760363053915), Value(data=0.5676924608493202)]\n",
      "15 {'loss': 0.7917135440851305}\n",
      "[Value(data=0.6308211105346955), Value(data=-0.5831222727977822), Value(data=-0.5029855475378354), Value(data=0.583584184042193)]\n",
      "16 {'loss': 0.7305055896001936}\n",
      "[Value(data=0.6460000607601427), Value(data=-0.5980042738223303), Value(data=-0.5230569204491364), Value(data=0.598317287982457)]\n",
      "17 {'loss': 0.6757402231121644}\n",
      "[Value(data=0.6600574346499326), Value(data=-0.6117862395466838), Value(data=-0.5418751071556577), Value(data=0.6120005546213114)]\n",
      "18 {'loss': 0.6266928585998996}\n",
      "[Value(data=0.6730876989648605), Value(data=-0.624562451310059), Value(data=-0.5594862891137764), Value(data=0.624730310386597)]\n",
      "19 {'loss': 0.5827046749556927}\n",
      "[Value(data=0.6851781516730678), Value(data=-0.6364224404088753), Value(data=-0.575950643088142), Value(data=0.6365925709406246)]\n",
      "20 {'loss': 0.543184254615129}\n",
      "[Value(data=0.6964093430118203), Value(data=-0.6474494673942435), Value(data=-0.5913359921401776), Value(data=0.6476645107225858)]\n",
      "21 {'loss': 0.5076057333755251}\n",
      "[Value(data=0.7068553607660353), Value(data=-0.6577198975584029), Value(data=-0.6057133361723814), Value(data=0.6580155500527047)]\n",
      "22 {'loss': 0.47550478531710916}\n",
      "[Value(data=0.7165841026698014), Value(data=-0.6673031275630656), Value(data=-0.6191537959803022), Value(data=0.6677082188850115)]\n",
      "23 {'loss': 0.44647343870158407}\n",
      "[Value(data=0.7256575808735348), Value(data=-0.6762618364062556), Value(data=-0.6317266000612816), Value(data=0.6767988823886985)]\n",
      "24 {'loss': 0.42015442102682876}\n",
      "[Value(data=0.7341322655938441), Value(data=-0.6846524136643926), Value(data=-0.6434978260444145), Value(data=0.6853383734097314)]\n",
      "25 {'loss': 0.3962354916894478}\n",
      "[Value(data=0.7420594589789427), Value(data=-0.692525471395073), Value(data=-0.6545296776059243), Value(data=0.6933725555696852)]\n",
      "26 {'loss': 0.37444404177599017}\n",
      "[Value(data=0.7494856853005436), Value(data=-0.6999263816050184), Value(data=-0.6648801334033387), Value(data=0.7009428297900372)]\n",
      "27 {'loss': 0.35454211436775007}\n",
      "[Value(data=0.7564530839283803), Value(data=-0.7068958045380908), Value(data=-0.6746028481799569), Value(data=0.708086591598499)]\n",
      "28 {'loss': 0.3363219141425474}\n",
      "[Value(data=0.7629997940018595), Value(data=-0.7134701881862234), Value(data=-0.6837472195541825), Value(data=0.7148376440220615)]\n",
      "29 {'loss': 0.3196018211077982}\n",
      "[Value(data=0.7691603226925914), Value(data=-0.7196822290892858), Value(data=-0.6923585590292765), Value(data=0.7212265697525615)]\n",
      "30 {'loss': 0.30422289092220683}\n",
      "[Value(data=0.7749658917204123), Value(data=-0.7255612905183787), Value(data=-0.700478324219512), Value(data=0.7272810658173813)]\n",
      "31 {'loss': 0.2900458064751823}\n",
      "[Value(data=0.780444759067465), Value(data=-0.7311337777812261), Value(data=-0.7081443827205741), Value(data=0.7330262438082711)]\n",
      "32 {'loss': 0.276948237103814}\n",
      "[Value(data=0.7856225145793065), Value(data=-0.7364234724870068), Value(data=-0.7153912877052973), Value(data=0.7384848986261995)]\n",
      "33 {'loss': 0.26482255947170535}\n",
      "[Value(data=0.7905223493989952), Value(data=-0.7414518287195991), Value(data=-0.7222505521838283), Value(data=0.7436777486071205)]\n",
      "34 {'loss': 0.2535738952950589}\n",
      "[Value(data=0.7951653000356859), Value(data=-0.7462382345616239), Value(data=-0.7287509136834328), Value(data=0.7486236497737501)]\n",
      "35 {'loss': 0.24311842418851481}\n",
      "[Value(data=0.7995704684134227), Value(data=-0.7508002425283072), Value(data=-0.7349185844434324), Value(data=0.7533397868081302)]\n",
      "36 {'loss': 0.23338193390129763}\n",
      "[Value(data=0.8037552195587384), Value(data=-0.7551537723664665), Value(data=-0.7407774845041433), Value(data=0.7578418431654323)]\n",
      "37 {'loss': 0.2242985744983258}\n",
      "[Value(data=0.8077353587331829), Value(data=-0.7593132894499084), Value(data=-0.7463494566016243), Value(data=0.762144152560576)]\n",
      "38 {'loss': 0.21580978724429925}\n",
      "[Value(data=0.8115252898503905), Value(data=-0.7632919617210684), Value(data=-0.7516544627846973), Value(data=0.76625983386483)]\n",
      "39 {'loss': 0.20786338287149364}\n",
      "[Value(data=0.8151381569753601), Value(data=-0.7671017978284365), Value(data=-0.7567107633068114), Value(data=0.7702009112569809)]\n",
      "40 {'loss': 0.2004127474590894}\n",
      "[Value(data=0.8185859706145496), Value(data=-0.7707537688130355), Value(data=-0.7615350787269954), Value(data=0.7739784212882208)]\n",
      "41 {'loss': 0.19341615729239747}\n",
      "[Value(data=0.8218797203892666), Value(data=-0.7742579154177163), Value(data=-0.7661427363623794), Value(data=0.777602508345225)]\n",
      "42 {'loss': 0.18683618681057207}\n",
      "[Value(data=0.8250294755556546), Value(data=-0.7776234428367079), Value(data=-0.7705478023267066), Value(data=0.7810825098340098)]\n",
      "43 {'loss': 0.18063919611780865}\n",
      "[Value(data=0.8280444747017626), Value(data=-0.7808588044921657), Value(data=-0.7747632004049239), Value(data=0.7844270322590935)]\n",
      "44 {'loss': 0.17479488656165004}\n",
      "[Value(data=0.8309332058218478), Value(data=-0.7839717762195552), Value(data=-0.7788008189811855), Value(data=0.7876440192383743)]\n",
      "45 {'loss': 0.16927591461203784}\n",
      "[Value(data=0.8337034778440284), Value(data=-0.7869695220633115), Value(data=-0.7826716071756062), Value(data=0.7907408123736298)]\n",
      "46 {'loss': 0.1640575557447879}\n",
      "[Value(data=0.8363624845718053), Value(data=-0.7898586527264906), Value(data=-0.7863856612669137), Value(data=0.7937242057889132)]\n",
      "47 {'loss': 0.1591174112792267}\n",
      "[Value(data=0.8389168618938703), Value(data=-0.792645277580788), Value(data=-0.7899523023925504), Value(data=0.7966004950534497)]\n",
      "48 {'loss': 0.1544351521743593}\n",
      "[Value(data=0.8413727390203146), Value(data=-0.7953350510241552), Value(data=-0.7933801464305049), Value(data=0.7993755211209057)]\n",
      "49 {'loss': 0.14999229467979008}\n",
      "[Value(data=0.843735784416664), Value(data=-0.7979332138700491), Value(data=-0.796677166881873), Value(data=0.8020547098420842)]\n",
      "50 {'loss': 0.14577200349164587}\n",
      "[Value(data=0.8460112470296347), Value(data=-0.80044463036312), Value(data=-0.7998507514920901), Value(data=0.8046431075421505)]\n",
      "51 {'loss': 0.14175891870134888}\n",
      "[Value(data=0.8482039933294983), Value(data=-0.8028738213390374), Value(data=-0.8029077532731722), Value(data=0.8071454130954823)]\n",
      "52 {'loss': 0.1379390033645257}\n",
      "[Value(data=0.8503185406327253), Value(data=-0.8052249939795257), Value(data=-0.8058545365197459), Value(data=0.8095660068802338)]\n",
      "53 {'loss': 0.1342994089740947}\n",
      "[Value(data=0.8523590871144592), Value(data=-0.807502068556113), Value(data=-0.8086970183482796), Value(data=0.8119089769499144)]\n",
      "54 {'loss': 0.1308283565087176}\n",
      "[Value(data=0.8543295388725808), Value(data=-0.8097087025063343), Value(data=-0.8114407062316397), Value(data=0.8141781427199508)]\n",
      "55 {'loss': 0.1275150310563275}\n",
      "[Value(data=0.8562335343630105), Value(data=-0.811848312143065), Value(data=-0.8140907319495748), Value(data=0.8163770764326755)]\n",
      "56 {'loss': 0.12434948829162151}\n",
      "[Value(data=0.8580744664888168), Value(data=-0.8139240922603831), Value(data=-0.8166518823296012), Value(data=0.8185091226338597)]\n",
      "57 {'loss': 0.1213225713239662}\n",
      "[Value(data=0.8598555025930644), Value(data=-0.8159390338670485), Value(data=-0.8191286271116018), Value(data=0.820577415867281)]\n",
      "58 {'loss': 0.11842583663463474}\n",
      "[Value(data=0.8615796025766259), Value(data=-0.8178959402506331), Value(data=-0.8215251442327807), Value(data=0.8225848967704185)]\n",
      "59 {'loss': 0.11565148799513864}\n",
      "[Value(data=0.8632495353369322), Value(data=-0.8197974415509803), Value(data=-0.8238453427970374), Value(data=0.8245343267337799)]\n",
      "60 {'loss': 0.1129923174061985}\n",
      "[Value(data=0.8648678937014129), Value(data=-0.8216460080004737), Value(data=-0.8260928839638907), Value(data=0.8264283012682716)]\n",
      "61 {'loss': 0.11044165222347439}\n",
      "[Value(data=0.8664371080098241), Value(data=-0.8234439619701134), Value(data=-0.8282711999664201), Value(data=0.8282692622090698)]\n",
      "62 {'loss': 0.10799330774478066}\n",
      "[Value(data=0.867959458482443), Value(data=-0.825193488944308), Value(data=-0.8303835114449367), Value(data=0.8300595088704024)]\n",
      "63 {'loss': 0.10564154462683223}\n",
      "[Value(data=0.8694370864959333), Value(data=-0.8268966475331881), Value(data=-0.8324328432629311), Value(data=0.8318012082532518)]\n",
      "64 {'loss': 0.10338103057993109}\n",
      "[Value(data=0.870872004875311), Value(data=-0.8285553786189466), Value(data=-0.8344220389539558), Value(data=0.8334964043970442)]\n",
      "65 {'loss': 0.10120680585829242}\n",
      "[Value(data=0.8722661072986381), Value(data=-0.8301715137219078), Value(data=-0.8363537739322567), Value(data=0.8351470269567092)]\n",
      "66 {'loss': 0.0991142521235781}\n",
      "[Value(data=0.8736211769006417), Value(data=-0.8317467826625585), Value(data=-0.8382305675859019), Value(data=0.8367548990779339)]\n",
      "67 {'loss': 0.09709906431101424}\n",
      "[Value(data=0.8749388941522505), Value(data=-0.8332828205874429), Value(data=-0.8400547943586829), Value(data=0.8383217446358525)]\n",
      "68 {'loss': 0.09515722517237848}\n",
      "[Value(data=0.8762208440848821), Value(data=-0.8347811744195041), Value(data=-0.8418286939159904), Value(data=0.8398491948956756)]\n",
      "69 {'loss': 0.09328498220914219}\n",
      "[Value(data=0.8774685229210978), Value(data=-0.8362433087869842), Value(data=-0.8435543804800182), Value(data=0.8413387946478031)]\n",
      "70 {'loss': 0.09147882674297546}\n",
      "[Value(data=0.8786833441668401), Value(data=-0.8376706114792999), Value(data=-0.845233851410913), Value(data=0.8427920078646497)]\n",
      "71 {'loss': 0.08973547490037348}\n",
      "[Value(data=0.8798666442147919), Value(data=-0.8390643984732656), Value(data=-0.8468689951026969), Value(data=0.8442102229216889)]\n",
      "72 {'loss': 0.08805185031395496}\n",
      "[Value(data=0.8810196875033417), Value(data=-0.8404259185685738), Value(data=-0.8484615982558613), Value(data=0.8455947574210183)]\n",
      "73 {'loss': 0.08642506836552805}\n",
      "[Value(data=0.8821436712711679), Value(data=-0.8417563576674832), Value(data=-0.8500133525823578), Value(data=0.8469468626519931)]\n",
      "74 {'loss': 0.084852421815752}\n",
      "[Value(data=0.883239729943437), Value(data=-0.8430568427301547), Value(data=-0.8515258609931977), Value(data=0.8482677277201268)]\n",
      "75 {'loss': 0.08333136768253374}\n",
      "[Value(data=0.884308939182078), Value(data=-0.8443284454339476), Value(data=-0.8530006433139601), Value(data=0.8495584833724633)]\n",
      "76 {'loss': 0.08185951524549055}\n",
      "[Value(data=0.885352319629394), Value(data=-0.8455721855622118), Value(data=-0.8544391415691056), Value(data=0.8508202055449483)]\n",
      "77 {'loss': 0.08043461506718293}\n",
      "[Value(data=0.8863708403714521), Value(data=-0.8467890341456297), Value(data=-0.8558427248720686), Value(data=0.8520539186549234)]\n",
      "78 {'loss': 0.07905454893359319}\n",
      "[Value(data=0.8873654221451462), Value(data=-0.8479799163769461), Value(data=-0.8572126939545738), Value(data=0.8532605986597182)]\n",
      "79 {'loss': 0.07771732062671592}\n",
      "[Value(data=0.888336940310564), Value(data=-0.8491457143179566), Value(data=-0.8585502853654771), Value(data=0.8544411759003827)]\n",
      "80 {'loss': 0.07642104745129741}\n",
      "[Value(data=0.8892862276082479), Value(data=-0.850287269415841), Value(data=-0.8598566753665903), Value(data=0.8555965377478657)]\n",
      "81 {'loss': 0.0751639524458865}\n",
      "[Value(data=0.8902140767191233), Value(data=-0.8514053848443505), Value(data=-0.8611329835504155), Value(data=0.8567275310673816)]\n",
      "82 {'loss': 0.0739443572155474}\n",
      "[Value(data=0.8911212426432213), Value(data=-0.8525008276839364), Value(data=-0.8623802762024297), Value(data=0.8578349645153047)]\n",
      "83 {'loss': 0.07276067532996429}\n",
      "[Value(data=0.8920084449118547), Value(data=-0.853574330953619), Value(data=-0.8635995694285025), Value(data=0.8589196106816582)]\n",
      "84 {'loss': 0.07161140623634102}\n",
      "[Value(data=0.8928763696465818), Value(data=-0.8546265955062601), Value(data=-0.8647918320661797), Value(data=0.8599822080901219)]\n",
      "85 {'loss': 0.07049512964153437}\n",
      "[Value(data=0.8937256714770947), Value(data=-0.8556582917978522), Value(data=-0.865957988396901), Value(data=0.8610234630664495)]\n",
      "86 {'loss': 0.06941050032235624}\n",
      "[Value(data=0.8945569753290981), Value(data=-0.8566700615405186), Value(data=-0.8670989206747097), Value(data=0.8620440514852492)]\n",
      "87 {'loss': 0.06835624332697883}\n",
      "[Value(data=0.8953708780922679), Value(data=-0.8576625192480661), Value(data=-0.8682154714856555), Value(data=0.863044620404237)]\n",
      "88 {'loss': 0.06733114953395783}\n",
      "[Value(data=0.896167950177507), Value(data=-0.858636253682175), Value(data=-0.8693084459508601), Value(data=0.8640257895943039)]\n",
      "89 {'loss': 0.06633407153858284}\n",
      "[Value(data=0.896948736971918), Value(data=-0.8595918292066254), Value(data=-0.8703786137851096), Value(data=0.864988152973042)]\n",
      "90 {'loss': 0.06536391983912487}\n",
      "[Value(data=0.8977137601991968), Value(data=-0.8605297870563293), Value(data=-0.8714267112218196), Value(data=0.865932279948746)]\n",
      "91 {'loss': 0.06441965929811905}\n",
      "[Value(data=0.8984635191924998), Value(data=-0.8614506465273831), Value(data=-0.8724534428143171), Value(data=0.8668587166813287)]\n",
      "92 {'loss': 0.06350030585611535}\n",
      "[Value(data=0.8991984920862466), Value(data=-0.8623549060938316), Value(data=-0.8734594831225456), Value(data=0.8677679872660716)]\n",
      "93 {'loss': 0.06260492347740353}\n",
      "[Value(data=0.8999191369327865), Value(data=-0.8632430444563768), Value(data=-0.8744454782935546), Value(data=0.8686605948456508)]\n",
      "94 {'loss': 0.061732621309071437}\n",
      "[Value(data=0.9006258927493668), Value(data=-0.8641155215278422), Value(data=-0.8754120475434456), Value(data=0.8695370226554546)]\n",
      "95 {'loss': 0.060882551036430685}\n",
      "[Value(data=0.9013191805004054), Value(data=-0.8649727793598128), Value(data=-0.8763597845478275), Value(data=0.8703977350068044)]\n",
      "96 {'loss': 0.06005390441935152}\n",
      "[Value(data=0.9019994040196563), Value(data=-0.8658152430145241), Value(data=-0.8772892587472664), Value(data=0.8712431782123365)]\n",
      "97 {'loss': 0.05924591099540927}\n",
      "[Value(data=0.9026669508765033), Value(data=-0.8666433213857551), Value(data=-0.878201016573697), Value(data=0.8720737814574745)]\n",
      "98 {'loss': 0.05845783593697087}\n",
      "[Value(data=0.90332219319027), Value(data=-0.8674574079721854), Value(data=-0.8790955826032991), Value(data=0.872889957621613)]\n",
      "99 {'loss': 0.05768897805046219}\n",
      "[Value(data=0.9039654883961378), Value(data=-0.8682578816064117), Value(data=-0.8799734606409005), Value(data=0.8736921040523693)]\n",
      "100 {'loss': 0.056938667907061535}\n",
      "[Value(data=0.9045971799659814), Value(data=-0.8690451071425742), Value(data=-0.8808351347405868), Value(data=0.8744806032959974)]\n",
      "101 {'loss': 0.056206266094974075}\n",
      "[Value(data=0.9052175980871756), Value(data=-0.8698194361053235), Value(data=-0.8816810701668322), Value(data=0.8752558237868349)]\n",
      "102 {'loss': 0.05549116158426741}\n",
      "[Value(data=0.905827060302196), Value(data=-0.8705812073026502), Value(data=-0.8825117143001409), Value(data=0.8760181204984376)]\n",
      "103 {'loss': 0.0547927701959975}\n",
      "[Value(data=0.9064258721116217), Value(data=-0.8713307474049166), Value(data=-0.8833274974908847), Value(data=0.8767678355588612)]\n",
      "104 {'loss': 0.054110533168035366}\n",
      "[Value(data=0.907014327542955), Value(data=-0.8720683714922536), Value(data=-0.8841288338647462), Value(data=0.877505298832376)]\n",
      "105 {'loss': 0.05344391581062198}\n",
      "[Value(data=0.9075927096874873), Value(data=-0.872794383572334), Value(data=-0.8849161220829319), Value(data=0.8782308284697329)]\n",
      "106 {'loss': 0.05279240624524175}\n",
      "[Value(data=0.908161291207285), Value(data=-0.8735090770703838), Value(data=-0.8856897460600738), Value(data=0.8789447314289405)]\n",
      "107 {'loss': 0.05215551422092098}\n",
      "[Value(data=0.9087203348142109), Value(data=-0.8742127352931613), Value(data=-0.8864500756425364), Value(data=0.8796473039683941)]\n",
      "108 {'loss': 0.05153277000251989}\n",
      "[Value(data=0.909270093722761), Value(data=-0.8749056318685126), Value(data=-0.8871974672496473), Value(data=0.8803388321140435)]\n",
      "109 {'loss': 0.050923723326018126}\n",
      "[Value(data=0.9098108120783679), Value(data=-0.875588031161999), Value(data=-0.8879322644801821), Value(data=0.8810195921021895)]\n",
      "110 {'loss': 0.05032794241618041}\n",
      "[Value(data=0.9103427253627048), Value(data=-0.8762601886719861), Value(data=-0.88865479868628), Value(data=0.8816898507993792)]\n",
      "111 {'loss': 0.049745013062345855}\n",
      "[Value(data=0.9108660607774155), Value(data=-0.8769223514044898), Value(data=-0.889365389516805), Value(data=0.8823498661007685)]\n",
      "112 {'loss': 0.049174537748410664}\n",
      "[Value(data=0.9113810376075981), Value(data=-0.8775747582289871), Value(data=-0.8900643454320271), Value(data=0.8829998873082378)]\n",
      "113 {'loss': 0.048616134833370635}\n",
      "[Value(data=0.9118878675662734), Value(data=-0.8782176402163137), Value(data=-0.8907519641913747), Value(data=0.8836401554894459)]\n",
      "114 {'loss': 0.04806943777906482}\n",
      "[Value(data=0.9123867551209882), Value(data=-0.8788512209597003), Value(data=-0.8914285333158793), Value(data=0.8842709038189406)]\n",
      "115 {'loss': 0.04753409442201108}\n",
      "[Value(data=0.9128778978036258), Value(data=-0.8794757168799262), Value(data=-0.8920943305268334), Value(data=0.8848923579023631)]\n",
      "116 {'loss': 0.04700976628645312}\n",
      "[Value(data=0.9133614865044187), Value(data=-0.8800913375155048), Value(data=-0.892749624162068), Value(data=0.8855047360847175)]\n",
      "117 {'loss': 0.04649612793595245}\n",
      "[Value(data=0.9138377057510966), Value(data=-0.8806982857987536), Value(data=-0.8933946735711767), Value(data=0.8861082497436146)]\n",
      "118 {'loss': 0.04599286636104931}\n",
      "[Value(data=0.9143067339740373), Value(data=-0.881296758318551), Value(data=-0.8940297294909062), Value(data=0.8867031035683389)]\n",
      "119 {'loss': 0.045499680400697955}\n",
      "[Value(data=0.9147687437582339), Value(data=-0.8818869455705273), Value(data=-0.8946550344018726), Value(data=0.8872894958255324)]\n",
      "120 {'loss': 0.04501628019534251}\n",
      "[Value(data=0.9152239020828346), Value(data=-0.8824690321953865), Value(data=-0.8952708228676701), Value(data=0.8878676186122421)]\n",
      "121 {'loss': 0.044542386669654446}\n",
      "[Value(data=0.9156723705489643), Value(data=-0.8830431972060195), Value(data=-0.8958773218573819), Value(data=0.888437658097026)]\n",
      "122 {'loss': 0.04407773104308852}\n",
      "[Value(data=0.9161143055964941), Value(data=-0.8836096142040171), Value(data=-0.8964747510524257), Value(data=0.8889997947497742)]\n",
      "123 {'loss': 0.04362205436654562}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Value(data=0.9165498587103741), Value(data=-0.8841684515861655), Value(data=-0.8970633231386221), Value(data=0.8895542035608547)]\n",
      "124 {'loss': 0.043175107083545855}\n",
      "[Value(data=0.9169791766171166), Value(data=-0.8847198727414587), Value(data=-0.8976432440843009), Value(data=0.8901010542501633)]\n",
      "125 {'loss': 0.04273664861442897}\n",
      "[Value(data=0.9174024014719697), Value(data=-0.8852640362391384), Value(data=-0.8982147134052215), Value(data=0.8906405114666144)]\n",
      "126 {'loss': 0.042306446962196306}\n",
      "[Value(data=0.9178196710372956), Value(data=-0.8858010960082359), Value(data=-0.8987779244170313), Value(data=0.8911727349785826)]\n",
      "127 {'loss': 0.04188427833870452}\n",
      "[Value(data=0.9182311188526281), Value(data=-0.8863312015090662), Value(data=-0.8993330644759362), Value(data=0.8916978798557693)]\n",
      "128 {'loss': 0.04146992681000695}\n",
      "[Value(data=0.9186368743968636), Value(data=-0.8868544978970919), Value(data=-0.8998803152082252), Value(data=0.8922160966429454)]\n",
      "129 {'loss': 0.04106318395971815}\n",
      "[Value(data=0.9190370632430036), Value(data=-0.8873711261795533), Value(data=-0.9004198527292411), Value(data=0.8927275315259903)]\n",
      "130 {'loss': 0.040663848569352956}\n",
      "[Value(data=0.9194318072058463), Value(data=-0.8878812233652371), Value(data=-0.9009518478523653), Value(data=0.8932323264906222)]\n",
      "131 {'loss': 0.04027172631465786}\n",
      "[Value(data=0.919821224483), Value(data=-0.8883849226077374), Value(data=-0.9014764662885378), Value(data=0.8937306194741992)]\n",
      "132 {'loss': 0.039886629477017335}\n",
      "[Value(data=0.9202054297895677), Value(data=-0.8888823533425312), Value(data=-0.9019938688368132), Value(data=0.8942225445109346)]\n",
      "133 {'loss': 0.039508376669078686}\n",
      "[Value(data=0.9205845344868319), Value(data=-0.8893736414181888), Value(data=-0.9025042115664156), Value(data=0.8947082318708663)]\n",
      "134 {'loss': 0.03913679257379018}\n",
      "[Value(data=0.9209586467052514), Value(data=-0.8898589092220038), Value(data=-0.9030076459907358), Value(data=0.8951878081928867)]\n",
      "135 {'loss': 0.038771707696101596}\n",
      "[Value(data=0.9213278714620579), Value(data=-0.8903382758003262), Value(data=-0.903504319233679), Value(data=0.8956613966121317)]\n",
      "136 {'loss': 0.03841295812662242}\n",
      "[Value(data=0.9216923107737321), Value(data=-0.8908118569738535), Value(data=-0.9039943741887576), Value(data=0.8961291168820064)]\n",
      "137 {'loss': 0.03806038531657617}\n",
      "[Value(data=0.9220520637636134), Value(data=-0.8912797654481297), Value(data=-0.9044779496712914), Value(data=0.896591085491107)]\n",
      "138 {'loss': 0.037713835863433375}\n",
      "[Value(data=0.922407226764891), Value(data=-0.8917421109194854), Value(data=-0.9049551805640638), Value(data=0.8970474157752927)]\n",
      "139 {'loss': 0.03737316130663923}\n",
      "[Value(data=0.9227578934192041), Value(data=-0.892199000176632), Value(data=-0.9054261979567604), Value(data=0.8974982180251359)]\n",
      "140 {'loss': 0.037038217932893275}\n",
      "[Value(data=0.9231041547710697), Value(data=-0.8926505371981291), Value(data=-0.9058911292794946), Value(data=0.8979435995889766)]\n",
      "141 {'loss': 0.0367088665904658}\n",
      "[Value(data=0.9234460993583419), Value(data=-0.8930968232459088), Value(data=-0.9063500984307158), Value(data=0.8983836649717879)]\n",
      "142 {'loss': 0.0363849725120718}\n",
      "[Value(data=0.9237838132988976), Value(data=-0.8935379569550516), Value(data=-0.9068032258997689), Value(data=0.8988185159300509)]\n",
      "143 {'loss': 0.03606640514584862}\n",
      "[Value(data=0.9241173803737301), Value(data=-0.8939740344199849), Value(data=-0.9072506288843687), Value(data=0.8992482515628281)]\n",
      "144 {'loss': 0.035753037994011985}\n",
      "[Value(data=0.9244468821066241), Value(data=-0.8944051492772738), Value(data=-0.9076924214032313), Value(data=0.8996729683992102)]\n",
      "145 {'loss': 0.03544474845878971}\n",
      "[Value(data=0.9247723978405749), Value(data=-0.8948313927851563), Value(data=-0.9081287144040956), Value(data=0.9000927604823066)]\n",
      "146 {'loss': 0.03514141769525681}\n",
      "[Value(data=0.925094004811107), Value(data=-0.8952528538999792), Value(data=-0.908559615867353), Value(data=0.9005077194499362)]\n",
      "147 {'loss': 0.03484293047071619}\n",
      "[Value(data=0.9254117782166383), Value(data=-0.8956696193496686), Value(data=-0.9089852309054921), Value(data=0.9009179346121722)]\n",
      "148 {'loss': 0.034549175030291375}\n",
      "[Value(data=0.9257257912860262), Value(data=-0.8960817737043754), Value(data=-0.9094056618585559), Value(data=0.9013234930258807)]\n",
      "149 {'loss': 0.03426004296841534}\n",
      "[Value(data=0.9260361153434298), Value(data=-0.8964893994444191), Value(data=-0.9098210083857954), Value(data=0.901724479566392)]\n",
      "150 {'loss': 0.03397542910591874}\n",
      "[Value(data=0.9263428198706097), Value(data=-0.8968925770256508), Value(data=-0.9102313675536974), Value(data=0.9021209769964298)]\n",
      "151 {'loss': 0.03369523137243759}\n",
      "[Value(data=0.9266459725667847), Value(data=-0.8972913849423523), Value(data=-0.9106368339205501), Value(data=0.902513066032423)]\n",
      "152 {'loss': 0.033419350693875034}\n",
      "[Value(data=0.9269456394061544), Value(data=-0.8976858997877756), Value(data=-0.9110374996177079), Value(data=0.9029008254083146)]\n",
      "153 {'loss': 0.03314769088466866}\n",
      "[Value(data=0.927241884693197), Value(data=-0.8980761963124306), Value(data=-0.9114334544277031), Value(data=0.9032843319369779)]\n",
      "154 {'loss': 0.03288015854462664}\n",
      "[Value(data=0.9275347711158384), Value(data=-0.8984623474802167), Value(data=-0.9118247858593463), Value(data=0.9036636605693443)]\n",
      "155 {'loss': 0.03261666296011082}\n",
      "[Value(data=0.9278243597965913), Value(data=-0.8988444245224902), Value(data=-0.9122115792199512), Value(data=0.9040388844513436)]\n",
      "156 {'loss': 0.03235711600935556}\n",
      "[Value(data=0.9281107103417521), Value(data=-0.8992224969901593), Value(data=-0.912593917684811), Value(data=0.9044100749787484)]\n",
      "157 {'loss': 0.032101432071724015}\n",
      "[Value(data=0.9283938808887422), Value(data=-0.8995966328038877), Value(data=-0.9129718823640495), Value(data=0.9047773018500141)]\n",
      "158 {'loss': 0.03184952794071316}\n",
      "[Value(data=0.9286739281516753), Value(data=-0.8999668983024894), Value(data=-0.9133455523669585), Value(data=0.9051406331172015)]\n",
      "159 {'loss': 0.03160132274052978}\n",
      "[Value(data=0.9289509074652277), Value(data=-0.9003333582895892), Value(data=-0.9137150048639362), Value(data=0.9055001352350581)]\n",
      "160 {'loss': 0.031356737846068905}\n",
      "[Value(data=0.9292248728268853), Value(data=-0.900696076078623), Value(data=-0.9140803151461263), Value(data=0.9058558731083417)]\n",
      "161 {'loss': 0.031115696806134824}\n",
      "[Value(data=0.9294958769376365), Value(data=-0.9010551135362448), Value(data=-0.9144415566828584), Value(data=0.9062079101374559)]\n",
      "162 {'loss': 0.030878125269754378}\n",
      "[Value(data=0.9297639712411786), Value(data=-0.9014105311242083), Value(data=-0.9147988011769859), Value(data=0.9065563082624676)]\n",
      "163 {'loss': 0.03064395091543845}\n",
      "[Value(data=0.9300292059617006), Value(data=-0.9017623879397859), Value(data=-0.9151521186182063), Value(data=0.9069011280055757)]\n",
      "164 {'loss': 0.03041310338325638}\n",
      "[Value(data=0.9302916301403008), Value(data=-0.9021107417547829), Value(data=-0.9155015773344555), Value(data=0.9072424285120929)]\n",
      "165 {'loss': 0.030185514209594626}\n",
      "[Value(data=0.9305512916701006), Value(data=-0.9024556490532045), Value(data=-0.915847244041451), Value(data=0.9075802675900017)]\n",
      "166 {'loss': 0.02996111676447783}\n",
      "[Value(data=0.9308082373301034), Value(data=-0.9027971650676332), Value(data=-0.9161891838904641), Value(data=0.907914701748141)]\n",
      "167 {'loss': 0.0297398461913365}\n",
      "[Value(data=0.931062512817856), Value(data=-0.9031353438143614), Value(data=-0.916527460514397), Value(data=0.908245786233083)]\n",
      "168 {'loss': 0.029521639349110868}\n",
      "[Value(data=0.9313141627809584), Value(data=-0.9034702381273378), Value(data=-0.91686213607223), Value(data=0.908573575064746)]\n",
      "169 {'loss': 0.02930643475658758}\n",
      "[Value(data=0.9315632308474702), Value(data=-0.9038018996909655), Value(data=-0.9171932712919086), Value(data=0.9088981210708004)]\n",
      "170 {'loss': 0.029094172538869718}\n",
      "[Value(data=0.93180975965526), Value(data=-0.9041303790718045), Value(data=-0.9175209255117364), Value(data=0.9092194759199106)]\n",
      "171 {'loss': 0.02888479437588554}\n",
      "[Value(data=0.9320537908803376), Value(data=-0.9044557257492172), Value(data=-0.9178451567203271), Value(data=0.909537690153862)]\n",
      "172 {'loss': 0.028678243452848}\n",
      "[Value(data=0.9322953652642129), Value(data=-0.9047779881449985), Value(data=-0.9181660215951832), Value(data=0.9098528132186143)]\n",
      "173 {'loss': 0.02847446441257844}\n",
      "[Value(data=0.9325345226403192), Value(data=-0.9050972136520326), Value(data=-0.9184835755399487), Value(data=0.9101648934943258)]\n",
      "174 {'loss': 0.028273403309614618}\n",
      "[Value(data=0.9327713019595383), Value(data=-0.90541344866201), Value(data=-0.9187978727203937), Value(data=0.9104739783243838)]\n",
      "175 {'loss': 0.028075007566026072}\n",
      "[Value(data=0.9330057413148621), Value(data=-0.9057267385922432), Value(data=-0.9191089660991771), Value(data=0.9107801140434859)]\n",
      "176 {'loss': 0.027879225928863875}\n",
      "[Value(data=0.933237877965227), Value(data=-0.9060371279116162), Value(data=-0.9194169074694402), Value(data=0.9110833460048025)]\n",
      "177 {'loss': 0.02768600842917436}\n",
      "[Value(data=0.9334677483585503), Value(data=-0.9063446601656966), Value(data=-0.9197217474872725), Value(data=0.9113837186062591)]\n",
      "178 {'loss': 0.02749530634251195}\n",
      "[Value(data=0.9336953881540032), Value(data=-0.9066493780010468), Value(data=-0.9200235357030974), Value(data=0.9116812753159703)]\n",
      "179 {'loss': 0.027307072150886912}\n",
      "[Value(data=0.9339208322435469), Value(data=-0.90695132318876), Value(data=-0.9203223205920165), Value(data=0.911976058696858)]\n",
      "180 {'loss': 0.027121259506088433}\n",
      "[Value(data=0.9341441147727614), Value(data=-0.907250536647254), Value(data=-0.9206181495831556), Value(data=0.9122681104304836)]\n",
      "181 {'loss': 0.026937823194325687}\n",
      "[Value(data=0.9343652691609944), Value(data=-0.9075470584643449), Value(data=-0.9209110690880481), Value(data=0.9125574713401247)]\n",
      "182 {'loss': 0.026756719102132592}\n",
      "[Value(data=0.9345843281208562), Value(data=-0.9078409279186332), Value(data=-0.921201124528095), Value(data=0.9128441814131232)]\n",
      "183 {'loss': 0.026577904183483728}\n",
      "[Value(data=0.9348013236770841), Value(data=-0.908132183500223), Value(data=-0.9214883603611325), Value(data=0.9131282798225321)]\n",
      "184 {'loss': 0.026401336428072738}\n",
      "[Value(data=0.9350162871848015), Value(data=-0.9084208629308006), Value(data=-0.9217728201071475), Value(data=0.9134098049480863)]\n",
      "185 {'loss': 0.02622697483070458}\n",
      "[Value(data=0.9352292493471932), Value(data=-0.9087070031830944), Value(data=-0.9220545463731655), Value(data=0.9136887943965228)]\n",
      "186 {'loss': 0.02605477936175832}\n",
      "[Value(data=0.9354402402326204), Value(data=-0.9089906404997407), Value(data=-0.9223335808773473), Value(data=0.9139652850212734)]\n",
      "187 {'loss': 0.02588471093867549}\n",
      "[Value(data=0.9356492892911935), Value(data=-0.9092718104115739), Value(data=-0.9226099644723209), Value(data=0.9142393129415519)]\n",
      "188 {'loss': 0.025716731398434386}\n",
      "[Value(data=0.935856425370825), Value(data=-0.9095505477553636), Value(data=-0.9228837371677775), Value(data=0.9145109135608595)]\n",
      "189 {'loss': 0.025550803470970565}\n",
      "[Value(data=0.9360616767327806), Value(data=-0.9098268866910169), Value(data=-0.9231549381523605), Value(data=0.9147801215849257)]\n",
      "190 {'loss': 0.025386890753505743}\n",
      "[Value(data=0.9362650710667465), Value(data=-0.9101008607182655), Value(data=-0.9234236058148696), Value(data=0.9150469710391097)]\n",
      "191 {'loss': 0.025224957685749918}\n",
      "[Value(data=0.9364666355054312), Value(data=-0.9103725026928559), Value(data=-0.9236897777648089), Value(data=0.9153114952852759)]\n",
      "192 {'loss': 0.025064969525941977}\n",
      "[Value(data=0.936666396638718), Value(data=-0.9106418448422596), Value(data=-0.9239534908522984), Value(data=0.9155737270381656)]\n",
      "193 {'loss': 0.024906892327696623}\n",
      "[Value(data=0.9368643805273846), Value(data=-0.910908918780919), Value(data=-0.9242147811873772), Value(data=0.9158336983812826)]\n",
      "194 {'loss': 0.024750692917625813}\n",
      "[Value(data=0.9370606127164047), Value(data=-0.9111737555250472), Value(data=-0.9244736841587148), Value(data=0.916091440782306)]\n",
      "195 {'loss': 0.024596338873705312}\n",
      "[Value(data=0.9372551182478477), Value(data=-0.9114363855069957), Value(data=-0.9247302344517544), Value(data=0.9163469851080512)]\n",
      "196 {'loss': 0.024443798504357524}\n",
      "[Value(data=0.9374479216733892), Value(data=-0.9116968385892034), Value(data=-0.9249844660663086), Value(data=0.916600361638992)]\n",
      "197 {'loss': 0.024293040828223395}\n",
      "[Value(data=0.9376390470664471), Value(data=-0.9119551440777444), Value(data=-0.9252364123336242), Value(data=0.916851600083358)]\n",
      "198 {'loss': 0.02414403555459725}\n",
      "[Value(data=0.9378285180339554), Value(data=-0.9122113307354865), Value(data=-0.9254861059329391), Value(data=0.9171007295908251)]\n",
      "199 {'loss': 0.023996753064499006}\n"
     ]
    }
   ],
   "source": [
    "# training the Model multiple times\n",
    "\n",
    "iterations_training = 200 # iterations_training\n",
    "\n",
    "print(\"Expected result:\\n\")\n",
    "print(ys)\n",
    "print(\"---------------------------------------\\n\")\n",
    "for k in range(iterations_training):\n",
    "    # Forward pass\n",
    "    ypred = [n(x) for x in xs] # predicted results from MLP for each group of inputs\n",
    "    loss = sum([(yout - ygt)**2 for ygt, yout in zip(ys, ypred)])\n",
    "    # zero grad to flush previous gradients\n",
    "    for p in n.parameters():\n",
    "        p.grad = 0.0\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    # Update\n",
    "    for p in n.parameters():\n",
    "        p.data += -0.01 * p.grad\n",
    "    # Show status\n",
    "    print(ypred)\n",
    "    print(k, {\"loss\": loss.data})\n",
    "    \n",
    "# if the step is too large and goes over the point where loss is close to zero, the loss will change values into something that will not make sense\n",
    "# to get closer to zero we could make the step size bigger with the risk of going over the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265bdcf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
